\chapter{Related Work}\label{ch:related}
Verification of assembly has been an active field of research for decades.
Binary analysis in general, both static and dynamic, has a rich history as well.
This chapter covers some of that history.

Up first in \cref{se:previous_assembly}
are some previous formal verification efforts that target assembly.
Following that is work on a lower level,
verification of the hardware that runs machine code, in \cref{se:hardware}.
After that is work in which assembly verification played a role
in a larger verification context, \cref{se:integrated_assembly},
and then verified compilation and static analysis tools are discussed
in \cref{se:verified,se:static_analysis}.
\Cref{related-table} provides an overview of the assembly,
hardware, and integrated projects.
It also includes the first two works presented in this dissertation.

Moving to a more categorical representation for the second half of this dissertation, we have the following two \lcnamecrefs{related-lifting}.
First, a set of works covering the lifting or extraction of control flow and state machines in \cref{related-lifting}, followed by a coverage of tools that perform exception analysis in \cref{related-exceptions} (with bottom-up approaches summarized in \cref{tab:eicfg-comparisons}).

\section{Assembly-Level Verification}\label{se:previous_assembly}
\Textcite{clutterbuck1986validation,clutterbuck1988verification} performed formal verification
of assembly programs using SPACE-8080\index{SPACE-8080}, a verifiable,
analyzable subset of the Intel 8080\index{Intel!8080} \ac{isa}.
Their work used \ac{spade} \autocite{carre1986spade}, a set of software tools for ``the efficient development, analysis, and formal verification of high-integrity software''.
\Ac{spade} provides \iac{fdl} for modeling programs
in order to analyze and formally verify them
using \iac{vcg}, proof checker, and symbolic interpreter.
They used automatic translation to model their SPACE-8080\index{SPACE-8080} program
in \ac{fdl}, and their verification methodology used the same kind of
annotated control-flow analysis as our Floyd-style approach
presented in \cref{ch:cfg} does, with additional assertions on state to avoid errors
and stronger conditions in order to prove functional correctness.
They also provided \emph{rewrite rules} that described the semantics
of the formal models in \ac{spade}. Unlike the work detailed in \cref{ch:cfg}, however,
they only covered a single 33-instruction function
with the verification methodology they presented.

Another usage of \ac{spade} for a more in-depth verification of assembly
was in the correctness proof of fuel control code for a Rolls-Royce
jet engine \autocite{oneill1988verification}. Once again,
it involved formulating a verification-friendly model of the Z8002 \ac{isa}
in \ac{spade}, the development of a Prolog translator from Z8002 assembly to \ac{fdl},
and the formalization of written specifications into proper pre- and postconditions
in \ac{spade}. \Ac{spade}'s proof checker was then used to validate the correctness
of the translated control code. While they assumedly covered many more instructions
than the previous \ac{spade} work did, the authors did not go into detail
on the amount of work that was actually done.
The only number given was that the specifications for about \SI{10}{\percent}
of the code modules under test were clarified
and one module received a code fix to improve its performance.

Similarly, \textcite{yu1993automated,boyer1996automated}
presented operational semantics and mechanized reasoning
for approximately \SI{80}\percent\ of the instructions of the MC68020 microprocessor, over \num{85}.
They implemented those semantics and mechanized their approach
in \ac{nqthm}, a precursor to the theorem prover ACL2 \autocite{ACL2}.
They then applied their mechanized reasoning to check functional correctness
for a binary search, quicksort, a standard \gls{c} string library, and others.
These early efforts required significant interaction,
as Yu and Boyer required over \num{19000}
lines of manually written proof to verify approximately \num{900} assembly instructions.
Compare this to the \num{1047} lines of manual proof
required to prove memory usage over \num{12252} assembly instructions.
Admittedly, they were verifying stronger properties,
which would greatly increase the amount of work required for verification,
but even then it's a significant difference.

Following that, \textcite{matthews2006verification}
targeted a simple machine model called TINY
as well as the M5 operational model of \ac{jvm} bitcode.
Their approach for functional correctness, implemented in ACL2,
utilized symbolic execution of operational semantics
over code annotated with manually written invariants
in order to generate \acp{vc} and then discharge them.
They even supported compositionality by verifying subcalls individually.
Both of the assembly-style languages they tested with feature a stack
for handling scratch variables rather than a register file
as \gls{x86}, \gls{arm}, and most other mainstream \acp{isa} do.
The case studies they verified were an implementation of the Fibonacci sequence,
a factorial function, and functions for \ac{cbc}-mode encryption and decryption.
In total, they covered \num{631} assembly instructions,
less than that handled by any of the methodologies presented in this dissertation.
Of course, they were targeting a stronger property than those works,
but they also did not perform any significant work to automate their approach.
All in all, however, this work is the closest to the Floyd-style approach
presented in \cref{ch:cfg} of any of the works presented in this chapter,
as they even implemented a version in Isabelle. Their Isabelle version did not support
compositionality, however.

Additionally, \textcite{goel2014syscalls,goelphd} presented an approach for modeling and verifying
non-deterministic programs on the binary level.
As with \textcite{matthews2006verification}, their work was implemented in ACL2.
In addition to formulating the semantics of most user-mode \gls{x86} instructions,
they provided semantics for common system calls.
System call semantics increase the spread of programs that can be fully verified.
Their work was applied to multiple small case studies,
including a word count program and two kernel-mode memory copying examples.

Ultimately, the main difference between the above-mentioned existing approaches
and the methodologies presented in \cref{memory-usage} of this dissertation lies in the degree of automation.
As stated previously, \ac{itp} over semantics of assembly instructions
does not scale under normal circumstances.
This is again due to the amount of intricate user interaction required.

Fully automated approaches to formal verification, however,
do not necessarily scale either.
The automated approach AUSPICE provided by \textcite{tan2015auspice}
takes about \SI6\hour\ to run on a 533-instruction string search algorithm.
This is despite the fact that, similar to our approaches, % todo: this sounds weird
they were targeting weaker safety properties
rather than going for functional correctness.
As another similarity to our approach in \cref{ch:syntax},
they too used a full set of Hoare rules in their analysis.
% todo: check the Hoare rules thing?

Though it is not a verification methodology by itself,
there is also \ac{dil}.
Developed by Myreen et al.\ in the HOL4 theorem prover \autocite{slind2008brief},
\ac{dil} uses operational semantics of machine code
to lift programs into a functional form.
That functional form can then be used in \pgls{hoare-logic} framework
for program analysis \autocite{myreen2007hoare}.
It formally covers the gap between machine code and \iac{hol} model
and allows for verification of properties in a theorem prover that utilizes that model.
\Ac{dil} has been used for both \gls{arm} and \gls{x86} \ac{isa} machine models
and applied to various large examples,
including benchmarks such as a garbage collector as well as the Skein hash function.
It has even been used as a component in a binary-level verification methodology
over the seL4 microkernel \autocite{sewell2013tvv}.

Also, \textcite{feng2006modular,feng2005sbca} presented stack abstractions
for modular verification of assembly code
in the Coq theorem prover \autocite{chlipala2013certified}.
Their work allows for integration
of various proof-carrying code systems \autocite{necula1997proof}.
As with the work presented in \cref{ch:syntax},
it utilizes a Hoare-style framework for its verification.
The authors applied their work to multiple example functions,
such as two factorial implementations
as well as \lstinline|setjmp| and \lstinline|longjmp|.
In contrast to the approach presented in \cref{ch:syntax},
though not that in \cref{ch:cfg},
manual annotations are required to provide information
regarding invariants and memory layout.

\Textcite{schlich2008phd} worked on the development of a model checker for analysis
of microcontroller assembly, \mcsquare.
Implemented in Java and supporting several microcontroller \acp{isa},
it uses multiple methods of state space reduction in order to avoid state space explosion
as much as possible. While it was applied to multiple case studies,
some of those case studies were only to analyze the effectiveness
of the various abstraction techniques used for state space reduction.

The most relevant case study to this dissertation was its application
to software compiled for an automotive microcontroller \autocite{schlich2007automotive}.
The three programs they focused on for their case study
were designed to record speed measurements from sensors on four wheels,
calculate the actual speed, and then transmit it over \iac{can} bus.\footnote{%
  \Iac{can} bus is a standard bus for electronic communications
  in automotive applications. \todo{this would be great as a glossary entry!}%
}
Some of the programs required simplification to be checkable,
so for consistency they applied, or at least attempted to apply,
the same simplifications to all three programs.
They did what they could to remove sends over the \ac{can} bus
and tried to focus on the speed signal from just one wheel rather than all four.
Ultimately, they were able to reason about all three programs
and prove both functional and non-functional properties of those programs.
On average they covered around \num{700} lines of \gls{c} or \num{2666} assembly instructions.
\begin{remark}[Function Isolation in Our Works]
  The case study on HermitCore in \cref{se:cfg_application} did involve isolating the functions under test before compiling them and covered less instructions.
  By contrast, the analyzed Xen functions in \cref{se:xen} were handled without any modification whatsoever to the Xen build process and covered even more instructions.
  Building on that, \cref{hg} had a combination of full-binary and per-function analyses with even more instructions for its Xen case study (\cref{hg-extraction}), while \cref{eicfg} was primarily per-binary but had unsound additional coverage via per-function fallbacks and went far beyond just Xen for its case study (\cref{eicfg-results}).
\end{remark}

\Textcite{brauer2009sba} intially performed static analysis of stack bounds
for the Atmel ATmega16 and Intel MCS-51 microcontrollers
in order to verify a lack of stack overflows.
Their work was applied to eight programs, four compiled for each microcontroller.
The functions compiled for the ATmega16 \ac{isa}
had previously been used to evaluate the effectiveness of \mcsquare.
They then embedded their static analysis in \mcsquare\ as a means to
improve the accuracy of \ac{dvr}, which \mcsquare\ uses for state space reduction.
While this stack safety approach is similar in focus to the memory usage works
I present here, the scope is much smaller.
Their focus was specifically on stack memory rather than memory in general.

Several years ago, \textcite{fromherz2019verified} embedded a subset
of the \gls{arch} \ac{isa} in the functional, verification-oriented language
F$^*$ \autocite{fstar}.
This was done in order to prove commonly-used crytographic routines
that mix \gls{c} with assembly for performance reasons are secure from information leakage.
The cryptographic routines they applied their work to were
Poly1305-\ac{aes} \autocite{bernstein2005poly1305} and
\ac{aes}-\ac{gcm} \autocite{dworkin2007recommendation}.
Their aim was to use F$^*$'s dependent type system to run a verified \ac{vcg}
during type checking, with the generated \acp{vc}
then being supplied to \iac{smt} solver.
The conditions on state to generate the \acp{vc} were expressed using Vale,
a language for assembly verification \autocite{bond2017vale}.
This was done in the style of \emph{proof by reflection} \autocite{bertot2004reflection}.
The \ac{vcg} itself, QuickCode, was formally proven sound in F$^*$ as well.
They measured performance of their verified algorithms, as one of them could be
transpiled to C. They also measured the performance of various versions
of their \ac{vcg}, and found that optimizing the \ac{smt} queries did improve performance
significantly.

Unlike our works in \cref{ch:cfg,ch:syntax}, the authors of this paper
had to do extra reasoning to ensure the \gls{c} and assembly code models were interoperable.
As we operated directly on full assembly, we did not have to worry about
that kind of interfacing. Both this work and the work presented in \cref{ch:syntax} used an explicit \ac{vcg},
but ours was proven correct by its Isabelle/HOL definitions;
we did not have to perform any additional work to ensure correctness
of the methodology.
Of course, as we implemented ours in an interactive theorem prover,
we could guide the \ac{vc} generation and discharging as needed.

\section{Hardware Verification}\label{se:hardware}
On a level lower than the assembly code level, or even the machine code level,
is the work done by hardware designers and testers
to verify the products that run those codes.
Quite often this is done with model checkers.

For example, \gls{arm} recently released several of their \acp{isa} in a machine-parsable,
executable format called \ac{asl}, a result that took five years to develop.
While not directly verifiable, the documents were automatically translated into
a verifiable form for use with a verification tool
called ISA-Formal \autocite{reid2016endtoend}.
ISA-Formal is intended to verify processor pipeline control
and has been successfully used for that purpose on multiple versions of the \gls{arm} \ac{isa}.
At its core, it uses bounded model checking for instruction sequence exploration.
They accomplished this by developing a translator from \ac{asl}
to the subset of System-Verilog that can be handled by commercial Verilog model checkers.

Not all of the components they worked with could be handled by the model checkers,
however; they restricted its usage to \ac{isa} analysis.
Alternative verification techniques were used for the components that the model checkers
could not handle, such as the \acp{fpu} and memory system.
These alternative techniques involved raising the abstraction level
and/or reducing the explored state space,
as their goal was not necessarily to detect all bugs in those specific units.
Instead, they wanted to check the correctness of the logic connecting them
to other processor elements, which they were successful at.

More recently, the Sail \ac{isa} specification language,
which supports automatic generation of emulation code
and of proof definitions for Isabelle, HOL4, and in some cases Coq,
has been used to provide rigorous semantic models of various \ac{risc} \acp{isa}
\autocite{armstrong2018models,armstrong2019isa}.
The \acp{isa} in question are \gls{arm}[v8.3-A], CHERI-MIPS, and RISC-V.
It was also used to produce a proof of correctness for a model of
\gls{arm}[v8-A] address translation in Isabelle.

\section{Integrated Assembly-Level Verification Efforts}\label{se:integrated_assembly}
A major verification effort based on \acl{dil}
was the verification of the seL4 kernel \autocite{klein2009sel4,Klein_AEMSKH_14}.
The seL4 project provides a microkernel written in formally proven correct \gls{c} code.
The tool AutoCorres is used for \gls{c} code verification \autocite{greenaway2012bridging}.
\Textcite{sewell2013tvv} verified a \emph{refinement relation} between the \gls{c} source code
and corresponding non-optimized and \lstinline|O2|-optimized \gls{arm} binaries.
The major differences with respect to our work
is that our methodology targets existing production code,
instead of code written with verification in mind.
For example, the seL4 source code does not allow taking the addresses of stack variables
(such as in \cref{fig:example2-c}):
their approach requires a static separation of stack and heap instead.

\Textcite{shi2012orientais} formally verified \iac{rtos} for automotive use
called ORIENTAIS.
Part of their approach involved source-level verification
using a combination of \gls{hoare-logic}
and abstract \ac{csp} model analysis \autocite{hoare1978csp}.
Binary verification was done by lifting the \ac{rtos} binary to xBIL,
a related hardware verification language \autocite{shi2012xbil}.
They translated requirements from the OSEK automotive industry standard
to source code annotations.
Ultimately, they proved properties such as deadlock-freedom, memory access safety,
and bounded response time in the presence of interrupts \autocite{shi2012interrupt}.
A similarity with our work was the usage of \gls{hoare-logic},
while the difference is that we performed verification solely on the assembly level
and with a more complex \ac{isa}.
We ultimately handled over \num{14631} \gls{arch} instructions compared to their \num{60}.
While they did handle \num{8000} lines of \gls{c} as well,
that is still a higher-level language than \gls{arch} assembly.

Targeting a similar case study as \cref{ch:syntax},
\textcite{dam2013hypervisor,dam2013formal}
formally verified a tiny \gls{arm}[v7] \emph{separation kernel},%
\index{separation kernel}
PROSPER, at the assembly level.
Separation kernels are similar to hypervisors,
providing isolation for individual components of a system and ensuring
only those components that are allowed to communicate do \autocite{rushby1981dvss}.
Their methodology integrated HOL4 with \ac{bap} \autocite{brumley2011bap}.
\Ac{bap} utilizes a custom intermediate language
that provides an architecture-agnostic representation of machine instructions
and their side effects.
First, the formal model of the \gls{arm} \ac{isa} provided by \textcite{fox2010arm} was used
in an HOL4 tool to translate the \gls{arm} binary into \ac{bap}'s intermediate language.
Following that, the \ac{smt} solver \ac{stp}  \autocite{ganesh2007stp}
was used to determine the targets of indirect branches
and to perform weakest-precondition computation with Hoare triples
to verify the user contracts.
While the approach was generally automated,
user input was still required to describe the contracts
the separation kernel was verified against.
An extension to the work is found in the HAPSOC project by \textcite{baumann2016high},
who did a similar proof for the \gls{arm}[v8-A] model provided by \textcite{fox2015improved}.

Finally, \textcite{bevier1989approach} presented a systems approach
to software verification that targeted correctness
all the way down to the hardware level.
All of their work was implemented in \ac{nqthm}.
\Textcite{hunt1989microprocessor} developed a general-purpose, 32-bit microprocessor,
FM8502, and proved that its gate-level specification
was an implementation of its formal \ac{isa}.
\Textcite{bevier1989short,bevier1989kit,bevier1987verified}
designed a small \ac{os} kernel, Kit, and proved that it implemented
``a fixed number of conceptually distributed communicating processes''
along with a set of typical kernel services and some security properties.
He did not prove that it could run on an FM8502, however;
it was executed on a more abstract model instead.
\Textcite{young1989generator} designed and proved the correctness of a code generator,
a major compiler component, for a subset of the Gypsy 2.05 programming language
\autocite{good1986gypsy}. That code generator's output was
the verified, high-level assembly language Piton \autocite{moore1988piton}.
\Textcite{moore1989language} then proved the correctness
of that language's FM8502 implementation.

\section{Verified Compilation}\label{se:verified}
In contrast to directly verifying machine or assembly code,
one can verify source code and then use \emph{verified compilation}.%
\index{verified compilation}
Verified compilation establishes that
the semantics of the output of the verified compiler
is equivalent to the semantics of the input,
so a program that has previously been verified correct
is verified to still be correct after compilation.

The CompCert project is one such verified compiler,
used by the seL4 project to reduce its \ac{tcb} \autocite{Klein_AEMSKH_14}.
It is written in a subset of C
called Clight \autocite{leroy:compcert,blazy2009clight},
though it itself is able to handle most components of the C99 standard.
The main difference between \gls{c} and Clight is that Clight is \emph{pure};
none of its operations have side effects. It also provides only one loop structure,
an infinite loop that must be broken out of to exit.
Clight has been mechanized in the Coq theorem prover with established
big-step operational semantics, making it a useful subset of C
for program verification work in Coq.

The full proof of \emph{semantic preservation},
as it is called in the CompCert documentation,
is based off of proofs of semantic preservation
for each step in CompCert's compilation process, of which there are twenty.
On top of that, it has eleven different intermediate languages for those steps,
all of which had to be proven semantically equivalent.

Another example of verified compilation is CakeML \autocite{kumar2014cakeml}.
It utilizes a (substantial)
subset of Standard ML modeled with big-step operational semantics in \ac{hol}.
Its main compiler frontend is designed to take ML-like \ac{hol} functions
and translate them to a CakeML \ac{ast}, which is then translated into machine code
using a verified backend. The compiler itself is bootstrapped,
meaning it can compile itself in \ac{hol}. It also provides support for using \gls{hoare-logic}
to perform post-hoc verification using a version of the CFML verification framework
\autocite{gueneau2017formulae,arthur2015union,chargueraud2011cfv}.

More recently, \textcite{chen2018compositional} produced a compositional framework
for the development of certified, \emph{interruptible}%
\index{interrupt}
\ac{os} kernels that use device drivers.%
\index{operating system!kernel}
This was previously a challenge due to the non-local and asynchronous behavior
of hardware interrupts. Their approach uses a general certified device model
with multiple instantiations and provides an effective model of device interrupts.
The verification was done in Coq with the kernel written in Clight.
Once verification was complete, the source code was compiled using a modified version
of CompCert to ensure the semantics were maintained.
They showed the value of their work by taking a preexisting,
non-interruptible, mostly-verified kernel, mCertiKOS \autocite{costanzo2016endtoend},
and extending it to work in their framework along with a couple of device drivers.
In order to deal with devices running in parallel with the \ac{cpu},
device interaction, drivers that are written in a mix of assembly and C,
and properly integrating the correctness proofs for individual components
of the system under test, they did the following.
First, they designed their system architecture such that each device driver
is given its own logical \ac{cpu}, running independently from the core of the kernel.
Then they designed an abstract model of interrupts
based on existing hardware implementations.
The correctness of the system as a whole was shown
by starting from a base machine model
and proving a refinement relation with each layer of abstraction placed on top of it.
As they started off with a mostly-verified kernel, it is likely they would have had
more difficulty if they had started with a kernel
not explicitly designed to be verified.

\section{Non-Formal Static Analysis}\label{se:static_analysis}
As a reminder, non-formal static analysis of binary code for the detection of bugs has also been an active research field for decades \autocite{kruegel2005automating,wang2017angr}.
This section covers some of the projects in that field from the past twenty years.

The BitBlaze project \autocite{song2008bitblaze,BitBlazeWebSite}
provides a tool called Vine that lifts \gls{x86} instructions to its own \ac{il} for assembly
in order to perform analyses on a higher level.
That language is fully-featured and can itself be compiled back down to assembly
if so desired.
In terms of analyses, Vine can construct \acp{cfg} for the lifted programs,
perform compiler-style dataflow analysis, generate dependency graphs,
and slice programs \autocite{weiser1981slicing,tip1995survey}.
Though Vine itself is not formally verified,
it does support interfacing with the aforementioned \ac{smt} solver \ac{stp}
as well as CVC Lite \autocite{barrett2004cvcl} and CVC3 \autocite{barrett2007cvc3}.
This allows for formal verification.

Meanwhile, the tool Infer \autocite{calcagno2011infer}, now developed at Facebook,
provides in-depth static analysis of LLVM code to detect bugs in programs
written in a variety of languages.
It utilizes separation logic \autocite{reynolds2002separation}
and bi-abduction to perform its analyses in an automated fashion.
It is designed to be integrated into compiler toolchains
in order to provide immediate feedback even in \ac{ci} scenarios.
For all the languages it handles, it checks for null pointer accesses
and other null-related issues as well as checking for language-specific
concurrency issues.
For C-style languages with a lower level of abstraction,
it also looks for memory leaks, performs linting for violations of coding conventions,
and checks for calls to mobile device \acp{api} that are not available
for the target device \ac{os}.
In Android code and Java in general, it ensures annotations can be reached,
looks out for mutability issues, and checks for resource leaks.

The static analysis tool FindBugs, written for Java code,
takes a bit of a different approach from those other two
\autocite{hovemeyer2004findbugs}.
Rather than performing control flow or dataflow analyses,
it searches Java bytecode for common (bad practice) code idioms
in order to detect likely bugs. Much like Infer,
some of the common errors it highlights include null pointer dereferences,
objects that compare equal not having equal hash codes,
and inconsistent synchronization.
It even provides a bug database that can be used to keep track of its warnings
throughout multiple iterations of development.

A somewhat older tool, Splint \autocite{evans2002static} detects buffer overflows
and similar potential security flaws in \gls{c} code.
Splint relies on annotated preconditions to derive postconditions
based on the syntactic structure of the code.
While their methodology is very similar to the formal technique of \gls{hoare-logic},
%described later on in this dissertation (\cref{se:hoare}),
they used heuristics for loop analysis rather than proper invariants
and thus could potentially miss bugs.
The annotations Splint uses are memory-focused, such as allowing users to specify
that certain variables should never be null or providing an emulation of
\lstinline|unique_ptr| functionality. It also does constraint analysis
and issues warnings when it encounters an expression it cannot determine
will not result in a bug, as well as checking for format string vulnerabilities.

The main difference between these static analysis tools and formal verification
is that these tools are generally highly suited to finding bugs
but are not able to prove their absence. This is due to a reliance on
efficient but incomplete techniques, such as depth-bounded searches.

\begin{table*}
  \centering
  \caption{Overview of related assembly verification and other work}\label{related-table}
  \begin{tabular}{l l l l l}
    \toprule
    \thead{Work} & \thead{Target} & \thead{Approach} & \thead{Applications} & \thead{Verified code} \\
    \midrule
    Clutterbuck,Carr\'e & SPACE-8080 & \acs*{itp}+\acs*{vcg} & Example func & \num{33} insts \\
    O'Neill et al. & Z8002 & \acs*{itp}+\acs*{vcg} & Jet engine code & \\
    Yu \& Boyer & MC68020 & \acs*{itp} & String funcs & \num{863} insts \\
    Matthews et al. & Tiny/JVM & \acs*{itp}+\acs*{vcg} & CBC enc/dec & \num{631} insts \\
    Goel et al. & \gls{arch} & \acs*{itp} & word-count  & \num{186} insts \\
    Tan et al. & \gls{arm}[v7] & ATP & String search & \num{983} insts \\
    Myreen et al. & \gls{arm}/\gls{x86} & \acs*{dil} & seL4 & \num{9500} \acs{sloc} \\
    Feng et al. & MIPS-like & \acs*{itp} & Example funcs & \\
    Schlich et al. & ATmega16 & MC & Auto funcs & Around 8k insts \\
    Brauer et al. & \makecell[l]{ATmega16\\Intel MCS-51} & SA+\acs*{mc} & Example progs &
      \makecell[l]{\num{2630} \acs{sloc}\\
        \num{935} \acs{sloc}} \\
    Fromherz et al. & \gls{c}/\gls{arch} & ATP+\acs*{vcg} & \acs{aes} funcs & \\
    \textbf{\Cref{ch:cfg}} & \gls{arch} & \acs*{itp}+\acs{vcg} & HermitCore & \num{2379}+ insts \\
    \textbf{\Cref{ch:syntax}} & \gls{arch} & CG,\acs*{itp},\acs{vcg} & Xen & \num{12252} insts \\
    \midrule
    Reid et al. & \acs*{asl} & MC+others & \gls{arm} \acp{isa} & \num{2209191}+ \acs{sloc} \\
    Sewell et al. & \gls{c} & \acs*{tv}+\acs*{dil} & seL4 & \num{9500} \acs{sloc} \\
    Shi et al. & \gls{c}/\gls{arm}[9] & \acs*{atp}+\acs*{mc} & ORIENTAIS & 8k \acs{sloc}, 60 insts \\
    Dam et al. & \gls{arm}[v7] & \acs*{atp}+UC & PROSPER & \num{3000} insts \\
    Baumann et al. & \gls{arm}[v8-A] & \acs*{atp}+UC & HAPSOC & \num{8000} \acs{sloc} \\
    Bevier et al. & PDP-11-like & \acs*{itp}+\acs*{tv} & Full system & 3k+ \acs{sloc}/insts \\
    \bottomrule
    \multicolumn{5}{c}{
      \small
      \newlength\colseplen
      \setlength\colseplen{1ex}
      \newcommand\colsep{\hspace\colseplen}
      \begin{tabular}{l@{\colsep}c@{\colsep}l l@{\colsep}c@{\colsep}l}
        \acs*{vcg} &=& Verification Condition Generation & \acs*{dil} &=& Decompilation into Logic \\
        \acs{sloc} &=& Source Lines of Code        & \acs*{atp} &=& Automated Theorem Proving \\
        UC   &=& User Contracts											& CG 	&=& Certificate Generation \\
        \acs*{tv}   &=& Translation Validation							& MC 	&=& Model Checking \\
        SA   &=& Static Analysis                    & \acs*{asl} &=& \acl*{asl}
      \end{tabular}
    }
  \end{tabular}
\end{table*}

\section{Lifting \Acsp*{cfg} from Binaries}\label{related-lifting}
We relate our work for \ac{hg} lifting to existing approaches for disassembly (\cref{related-disassembly}), binary decompilation (\cref{related-decompilation}), binary verification (\cref{related-hg-verification}), and abstract interpretation (\cref{related-absint}), as well as ones that learn state machines from black-box implementations (\cref{related-automata}).
To the best of our knowledge, the only existing work that has similar focus on disassembly based on formal methods is Jakstab \autocite{kinder2010static,kinder2012alternating,kinder2012virtualization}, which we therefore discuss in more detail.

\todo{comparison figure if I have time?}

\subsection{Jakstab}\label{related-jakstab}
Jakstab performs binary analysis and control flow reconstruction by utilizing abstract interpretation, like those works in \cref{related-absint}.
Its main analysis was designed for binaries with potentially handcrafted, obfuscated behavior (such as device drivers and malware),
and much like our \ac{hg} lifting, it uses a form of at-will disassembly.
This means that only specific series of bytes queried from specific locations in the binary are disassembled.

Unlike our lifting work, Jakstab often requires usage of manually-coded harnesses for binaries.
A harness provides property specification and additional intermediate operations not found in the actual binary, and possibly external call modeling.
They may additionally be used to provide pointer initialization for library/driver code.
However, an imprecise harness may lead to false positives requiring manual investigation, and that kind of harness is impossible to create precisely for \ac{cots} binaries, such as the binaries used in our case studies.
Because of this, Jakstab offers a variety of heuristics to improve scalability and precision at the cost of making the results possibly unsound  \autocite[129]{kinder2010static}.

Additionally, we argue that Jakstab is not overapproximative even for those sound cases.
That is, even when no indirections occur, it will not always reach all instructions that are actually reachable in a binary.
The instructions and states that are reached by Jakstab
are \emph{relative to the harness}; that is, relative to some initialization
and external information.
In contrast, we make much fewer assumptions about the initial state and conditions.
Furthermore, Jakstab's average coverage is only \SI{15}\percent\ of the instructions that are present in a binary \autocite[Table~6.2]{kinder2010static}.
This percentage is computed exclusively over the case studies where it reports a complete and successful result (no counterexamples found for the property being checked).
In general, programs do not normally exhibit that much dead code.
Therefore Jakstab appears to underapproximate rather than overapproximate.
% A sound overapproximative approach should explore---in the case of a successful exploration effort---%
% 100\% of all viable instructions reachable from the main function,
% though that does not necessarily correspond to 100\% of existing instructions.
% In our case, the average percentage of explored instructions in case of successful exploration (successful completion, no unresolved indirections)
% is 56\%.
% The remaining 44\% is dead code
% and code that is not contained in the body of the program
% due to being present in functions only handled by the runtime library
% (pre-start constructors, post-exit destructors, signal handlers, etc.).

Also, Jakstab takes a slightly different approach to calculating \acp{lfp}.
Rather than performing a join operation that may produce range bounds,
it instead keeps track of a certain number of values for each ``variable'' (register, memory location).\index{symbolic!variable}
Once that number is exceeded, the possible values are widened to an unknown (akin to \gls{bot}), though pointer type is preserved when possible.
This operation does not appear to be utilized when control flow recombines
after conditional statement divergence, however.
Because of that, it results in a larger state space overall than our \ac{hg} lifting work, though potentially a more precise one.

Related to this is Jakstab's memory handling approach.
Unlike our more fine-grained memory model approach (described later in \cref{sec:memory-models}), it is all-or-nothing.
This means it cannot handle writes to fully-unknown
(or on-the-stack-but-exact-location-unknown) memory regions,
as it will end up with overwritten return addresses in all such cases.
While Jakstab can be configured to continue execution in such scenarios,
the developers considered the results too imprecise for practical usage.
Our lifting tool, meanwhile, is able to handle most such situations
as it provides memory models for standard aliasing conditions.

\begin{remark}[Issues using Jakstab]
  We were not able to directly compare the behavior of Jakstab with our lifting mechanism.
  Jakstab on its own did not work due to unsound assumptions on the structure of \ac{elf} binaries.\fturl{https://github.com/jkinder/jakstab/issues/9}
  \todo{make a citation instead?}
  This is likely due to its development being primarily focused on the handling of Windows programs.
  Even so, while were able to successfully test with a modified version \autocite{peterson2019},%
  \fturl{https://github.com/tpetersonkth/AlternatingControlFlowReconstruction/}
  \todo{the footnote should be a citation too}
  we were not able to do a comparison as Jakstab does not support 64-bit binaries.
\end{remark}

\subsection{Disassembly}\label{related-disassembly}
Disassemblers are tools that take a binary and lift it to an assembly language.
Traditionally, there are two main methods of disassembly: \emph{linear sweep}
and \emph{recursive traversal} \autocite{schwartz2002disassembly}.
Modern disassemblers may combine the two or use other techniques like probabilistic \autocite{wartell2011differentiating,wartell2014shingled,miller2019probabilistic} or conflict analyses \autocite{khadra2016speculative}.

Linear sweep disassemblers, such as GNU's\index{GNU}
\lstinline|objdump|, scan through a binary linearly
in areas where code is typically encountered
to extract instructions \autocite{schwartz2002disassembly}.
Linear sweep algorithms are easy to implement but well-known to be unsound \autocite{schwartz2002disassembly}.
\Acp{isa} with variable-length instructions/non-strict alignment requirements, such as \gls{x86}, pose problems to such disassemblers when complex indirect jumps are involved.
Intermixed code and data also pose a problem.
The lack of reachability analysis can also cause problems for code after function calls even when they are calls to internal functions.
This is because, unless the disassembler does multiple sweeps, it cannot identify non-returning functions, though heuristics may be able to help with making reasonable assumptions.

Recursive traversal algorithms are more complex than linear sweep.
They operate by starting from some initial instruction and then trace the possible paths of execution, interpreting instructions as they proceed \autocite{schwartz2002disassembly,kruegel2004static}.
Our work in \cref{hg} is an example of a recursive traversal disassembler, with \cref{eicfg} using a similar methodology.
This allows higher accuracy than linear sweep.
For example, such disassemblers support cases where parts of instructions can be interpreted as other instructions, possible with \acp{isa} having unaligned/variable-length instructions.
They will also be more likely to exclude code that is not executed.
The major challenge of recursive traversal is properly dealing with indirect calls and jumps.
A tool that primarily uses recursive traversal is IDA Pro \autocite{ida}, intended for interactive debugging and reverse engineering.
Typically, existing approaches to recursive traversal use heuristics or guesses to approximate indirect branches.

Probabilistic approaches to disassembly \autocite{khadra2016speculative,miller2019probabilistic} include machine learning techniques, such as BYTEWEIGHT \autocite{bao2014byteweight} or the works of \textcite{wartell2011differentiating,wartell2014shingled}.
In general, these techniques attempt to identify sequences of bytes as instructions based on their context, using large amounts of \emph{training sets} as a guide.
The approach of \textcite{miller2019probabilistic} identifies the probability of byte sequences representing instructions based on the context.
It uses manually derived \emph{hints} rather than training sets.
Spedi by \textcite{khadra2016speculative} provides a speculative, conflict analysis-based approach.
This approach involves scanning through a binary and speculatively extracting basic blocks of instructions and then eliminating infeasible possibilities via a conflict analysis process.
While it is able to handle switch statements (jump tables), it does not handle other types of indirection.
The main disadvantage of probabilistic/speculative techniques is that they inherently cannot provably overapproximate the behavior of the binary.
Although they typically have very few cases of underapproximation, such cases are not impossible.

The key differences between our lifting work and existing disassemblers are that:
\begin{enumerate}
  \item no existing disassembler aims at providing a guarantee that the lifted representation is a sound overapproximation of the binary; and
  \item our approach goes beyond disassembly, providing both control flow and invariants that are sufficiently strong enough to prove control flow.
\end{enumerate}
The cost of our approach is that it may fail, whereas other approaches are able to guess or use heuristics to continue.

\subsection{Binary Decompilation}\label{related-decompilation}
\todo{some more!: 10.1002/spe.4380250706, 10.1109/SANER.2018.8330222}

As mentioned in the introduction to this dissertation, a decompiler takes a binary or other low-level source as input and lifts it to a higher-level representation.
RetDec \autocite{retdec}, Phoenix \autocite{brumley2013native}, and FoxDec \autocite{verbeek2020sound} all aim at lifting a binary to \gls{c} code.
SmartDec \autocite{fokin2011smartdec} lifts to \gls{cpp} code, whereas McSema \autocite{dinaburg2014mcsema} lifts to LLVM\index{LLVM}.
Ramblr \autocite{wang2017ramblr} lifts a binary to \emph{symbolized} assembly, where concrete addresses are replaced with symbolic labels.
CodeSurfer/\gls{x86} \autocite{balakrishnan2004analyzing,balakrishnan2005codesurfer}
provides a graphical interface for lifting binaries to an intermediate representation and interactively analyzing them.
Additionally, decompilers are often integrated into reverse engineering and program exploration tools such as IDA Pro \autocite{ida-decompiler},
Binary Ninja \autocite{binary-ninja-decompiler}, and Ghidra \autocite{ghidra}.

A key factor in decompilation approaches, and also in other approaches that aim at producing control flow graphs or dataflow analyses, is that many of them assume that disassembly has been done by an external tool that is assumed to be sound.
Our algorithm thus \emph{complements} these works.
For example, McSema requires an external source of control flow information, which could be generated from our solution.

For a more formal approach, we return to \ac{dil} \autocite{myreen2007hoare,myreen2012dil}.
However, \ac{dil} does not deal with indirect branching and \emph{assumes} that return addresses are not overwritten.
In their own words, ``[its] heuristic is easily confused by computed branches'' \autocite{myreen2008dil}.
In contrast, our \ac{hg} lifting approach supports various forms of indirect branches and can detect potentially-overwritten return addresses.

\subsection{Relation to Binary Verification}\label{related-hg-verification}
As a reminder, binary verification techniques aim to prove properties on the machine code level \autocite{kumar2018software}.
Typically, binary verification aims at proving that the binary is correct with respect to some higher-level artifact (source code or a specification).
\Textcite{klein2009sel4,klein2010refinement,sewell2013tvv} used a refinement-based approach to verify the seL4\index{seL4} microkernel binary.
\Textcite{kamkin2020deductive} developed a methodology for verifying that the machine code of RISC-V\index{RISC-V} binaries satisfy annotations in the binaries' source code.
For a top-down approach, proof-carrying code \autocite{necula1997proof}
integrates a proof of correctness into the binary that is verified at runtime.
If the proof fails, the binary cannot be executed.
This does require some additional functionality, with both the compiler and the program host needing to support it.

In contrast, our \ac{hg} lifting approach is targeted at the scenario where a higher-level artifact such as source code or a specification is not available.
In such contexts, most approaches are interactive \autocite{goel2014syscalls,goelphd,verbeek2019refinement}.
Even our Hoare-style work presented in \cref{ch:syntax}, tailored to memory usage properties, has a ``manual effort vs. instruction count ratio'' of roughly 1 to 11 \cite{verbeek2020automated}.
\Textcite{tan2015auspice} provided a fully automated method, AUSPICE, that takes about \SI6\hour\ for a \num{533}-instruction string search algorithm.
Our \ac{hg} lifting approach \emph{complements} formal verifiers that generate invariants for proving functional correctness.
\begin{remark}[Lifting in the \acs*{tcb}]
  The invariants this lifting approach generates do not contain enough information to prove full functional correctness; they are tailored for control flow and pointer relations.
  The tool instead serves to remove the lifting process from the \ac{tcb}.
  This is useful because verification based on untrustworthy disassemblers and control flow reconstruction is itself untrustworthy.
\end{remark}

\subsection{Abstract Interpretation}\label{related-absint}
The general problem of lifting binary code from a string of zeroes and ones to a higher-level form is known to be undecidable.
Thus, approximate solutions have been extensively studied, especially in the framework of \emph{abstract interpretation} \autocite{cousot1976static,cousot1977abstract}.
Such an approach gives mathematical foundations to reason about approximations and their computations.% (elaborated on in \cref{background-absint}).

\Textcite{bardin2011bincoa,daniel2020binsec} provided Binsec, which utilizes abstract interpretation in the process of information flow analysis for cryptographic implementations.
\Textcite{zhang2019bda} provided a path sampling algorithm and use abstract interpretation to prune infeasible paths.
Meanwhile, \textcite{reinbacher2011test} used abstract interpretation in a similar fashion for binary-level test case generation.
These works aim at orthogonal usages of abstract interpretation with respect to our \ac{hg} lifting work, as they \emph{assume} availability of a tool that provides overapproximative control flow.
Our approach is thus highly complementary to them.

Moving on: BinTrimmer, developed by \textcite{redini2019b}, uses abstract interpretation to refine \acp{cfg} from binaries for debloating.
Its deal with indirect branches in an overapproximative fashion.
The key distinction between our \ac{hg} approach and BinTrimmer is that it is \emph{solely} concerned with indirections.
Other properties of assembly programs are not a consideration.
These include security properties such as control flow integrity (return addresses are not overwritten and jumps/calls go where they are supposed to), avoidance of stack overflows, etc.
BinTrimmer also does not provide invariants with sufficient strength to serve as evidence for overapproximation.
Moreover, BinTrimmers' case studies are six hand-picked binaries containing up to \num{555} \ac{sloc}, in contrast to the \ac{hg} Xen Hypervisor case study presented in \cref{hg-extraction}.

Finally, while not a binary lifting approach, the tool Crab \autocite{crab}, uses abstract interpretation for loop invariant restriction \autocite{gange2016abstract}.
This tool is part of the SeaHorn verification framework for LLVM \ac{ir} \autocite{seahorn}.

\subsection{Automata Learning}\label{related-automata}
Automata learning algorithms are a different approach to state machine extraction.
They perform black-box testing in order to \emph{learn} the behavior of a system \autocite{steffen2011active}.
For example, \textcite{fiter2017ssh} used automata learning to infer the functionality of three \ac{ssh} server implementations.
Their learning methodology was based on LearnLib \autocite{raffelt2005learnlib}, an automata learning library.
Automata learning typically produces abstract high-level models concerning the in/output relations at the protocol level.
Their \emph{mapper}, which maps back and forth from abstract inputs/outputs to concrete packages to be sent to/received from the server,
was based on the Paramiko\fturl{https://www.paramiko.org/}
\ac{ssh} client implementation.

\Textcite{kerkers2017assessing} performed security analysis
of power distribution \acp{ics} using automata learning.
LearnLib was again used to provide the necessary learning features.
In addition to implementing a mapper to support the necessary \ac{ics}
protocols, Kerkers also had to provide software and hardware testing interfaces for the physical \acp{ics} that were under test.

Automata learning techniques can be used to infer state machines when source code is not available.
However, they do not provide formal statements of overapproximation.
They also require development of a \emph{mapper}, which translates between the learner and the black box.
Developing such a mapper is a significant per-binary manual effort.
Its implementation has a severe impact on the validity of the inferred state machine.
In contrast, our disassembly approach does not require such manual effort.

\section{Exception Handling Analysis}\label{related-exceptions}
The two main approaches to analyzing exceptional behavior for \gls{cpp} programs, and behavioral program analysis in general, are bottom-up and top-down.
Bottom-up tools include decompilers and disassemblers, as well as this work.
Top-down tools focus on analysis of source code or other higher-level representations.

\subsection{Bottom-Up Approaches: Decompilers and Disassemblers}
We provide a summary of such works in \cref{tab:eicfg-comparisons}.
The table describes whether or not the works do intra- or interprocedural exception analysis and if so, if it is static or dynamic.
Static approaches, such as the one presented in this paper, typically aim for overapproximation.
They utilize abstraction or other methods to model paths symbolically.
In contrast, dynamic approaches are inherently underapproximative.
This is because they rely on concrete runtime behavior and evaluating all possible concrete paths is infeasible.
Even works that hijack runtime control flow to force specific path execution must do it in a sampled fashion \autocite{wilhelm2007forced}.
\begin{table}
  \centering
  \begin{threeparttable}
    \caption{Bottom-up Exceptional Analysis Comparisons}\label{tab:eicfg-comparisons}
    \begin{tabular}{llll}
      \toprule
      Program & Intraproc.\tnote\dag & Interproc.\tnote\ddag & Academic Evals \\
      \midrule
      \textbf{\acs*{eicfg} work} & \textbf{Statically} & \textbf{Statically} & \\
      Binary Ninja & Statically\tnote{*} & Dynamically & \\
      IDA Pro & Statically & Dynamically & \autocite{g2019idapro,liu2020correctness} \\
      Ghidra & Statically & Dynamically & \autocite{rohleder2019ghidra,pang2021sok,liu2020correctness} \\
      McSema \autocite{mcsema,mcsema-exceptions} & Statically & No & \autocite{pang2021sok,dasgupta2020scalable} \\
      RetDec & Unknown & No & \autocite{liu2020correctness} \\
      \bottomrule
    \end{tabular}
    \begin{tablenotes}
      \item[\dag] Can it identify the landing pads in a function?
      \item[\ddag] Can it trace from (re)throw to landing pad?
      \item[*] Via \url{https://github.com/EliseZeroTwo/SEH-Helper}
    \end{tablenotes}
  \end{threeparttable}
\end{table}

While Binary Ninja \autocite{binary-ninja}, IDA Pro \autocite{ida}, and Ghidra \autocite{ghidra} all support some form of intraprocedural \ac{eh} analysis, they can only perform interprocedural \ac{eh} analysis dynamically via debugging.
For example, Ghidra provides default, platform-dependent analyses that extract try-catch block information and other landing pad information for \ac{eh}.
However, it does not provide unwinding control flow in the generated block/call graphs, only cross-references for the $\landingpadtable$.
This means that it can identify landing pads and analyze the code following them, but it cannot identify the exceptions that will reach them.
Its built-in debugger that can perform unwinding is also ultimately just an interface to external, dynamic debugging tools such as \ac{gdb} or \href{https://lldb.llvm.org/}{LLDB},
which perform dynamic analysis and instrumentation. Traces are also supported,
but those require the program to have been run previously.

McSema \autocite{mcsema} is back too! It is relevant because its decompilation process lifts machine code to LLVM bitcode.
This allows providing intraprocedural exception analysis by generating the LLVM representation for exception landing pads \autocite{mcsema-exceptions}.
However, it does not perform interprocedural analysis as it merely lifts to LLVM bitcode rather than tracing the execution of exceptions from throw site to landing pad.

RetDec \autocite{retdec} functions similarly to McSema as a decompiler-to-LLVM, though it also supports \gls{c} output.
However, we could not find information about its ability, or lack thereof, to deal with \ac{eh}. We also were unable to successfully apply it to programs using \gls{cpp} exceptions.
Furthermore, even when it does work it suffers from accuracy issues and produces non-semantically-equivalent results, many of which do not even run \autocite{foudree2019regsym}.
As with McSema, it does not perfom interprocedural exception analysis.

\subsection{Top-Down Approaches}
By contrast, there are tools that analyze exceptions from the source-code side.
This prevents the analysis of legacy code without source but allows for better static analysis during development, or even formal proofs of correctness of the exceptional semantics.

\Textcite{hutton2004compiling} provided basic formal semantics for source-level \gls{cpp}-like exceptions.
They accompanied this with a compiler for a small language with exceptions and a proof of correctness of that compilation.
This is different from our approach as we do not aim to verify the correctness of exceptional behavior due to our lack of ground truth (source code or some program specification).

\Textcite{prabhu2011interprocedural} provide source-level generation of \acp{iecfg} for \gls{cpp} exceptions.
These \acp{iecfg} are much like our \acp{eicfg}, but for source code.
Unlike our work, however, \acp{iecfg} are used to \emph{eliminate} exceptions when compiling to a binary to make static analysis easier.
They cannot be used to analyze already-compiled programs with exceptions.

Java programs use exceptions as well. \Textcite{kechagia2019misuse} provide a tool for identifying unhandled \ac{api} misuses via static exception propagation and test case generation. This differs from our work as we detect in-program exceptional behavior, not exceptions produced by \ac{api} or other external calls.

\subsection{Tools that use \texttt{libunwind}}
A standard library for instrumented/dynamic unwinding is \lstinline|libunwind| \autocite{libunwind}.
It has been utilized by tools such as RockJIT, which protects \ac{jit} compilers by enforcing \ac{cfi} \autocite{niu2014rockjit}.
It can function without source code. However, as an instrumenting library, it requires a running program and thus must operate dynamically.

Our final tool, as well as all of the other bottom-up analysis tools mentioned above, assumes both the existence and correctness of the \inlineasm{.eh_frame} and \inlineasm{.gcc_except_table} \ac{elf} sections.
However, neither of those cases are guaranteed.
To deal with such scenarios, \textcite{bastian2019dwarf} provide tools for the validation as well as synthesis of exception-handling-related table-based unwinding information.

%\subsection{Component-based Approaches}
%There are also tools for validating and verifying fault handling behavior
%for software systems that involve high-level component-based development:
%
%\todo{figure out if this is worth it}
%
%\url{https://www.researchgate.net/publication/3921585_Exception_handling_in_component-based_system_development},
%
%\url{https://link.springer.com/chapter/10.1007/11572329_8},
%
%\url{https://journal-bcs.springeropen.com/articles/10.1007/BF03192362}.

\section{Summary}
This section covered some of the work related to that presented in this dissertation.
Previous assembly- and hardware-level formal verification efforts,
verification efforts containing assembly or binary analysis components,
verified compilation, and non-formal static analysis tools were all discussed.
We also covered various tools and approaches for lifting or extracting control flow graphs/state machines from binaries as well as ones that perform exception-aware analyses.

Notably, while multiple assembly-level verification efforts
presented in this chapter achieved more coverage
than the over \num{2379} instructions achieved by the work in \cref{ch:cfg},
none appear to have achieved the \num{12252}
verified instructions covered in \cref{ch:syntax} except the work produced by
Arm\index{Arm Ltd.} employees.
We then built further on that with our approaches in \cref{hg}, covering \glssymbol{inst-total-lifted} instructions, and \cref{eicfg}, covering \glssymbol{eicfg-inst-total} instructions.
