\chapter{Related Work}\label{ch:related}
Verification of assembly has been an active field of research for decades.
This chapter covers some of that history.

Up first in \cref{se:previous_assembly}
are some previous formal verification efforts that target assembly.
Following that is work on a lower level,
verification of the hardware that runs machine code, in \cref{se:hardware}.
After that is work in which assembly verification played a role
in a larger verification context, \cref{se:integrated_assembly},
and then verified compilation and static analysis tools are discussed
in \cref{se:verified,se:static_analysis}.
\Cref{related-table} provides an overview of the assembly,
hardware, and integrated projects.
It also includes the works presented in this dissertation.

\section{Assembly-Level Verification}\label{se:previous_assembly}
\textcite{clutterbuck1988verification} performed formal verification
of assembly programs using SPACE-8080, a verifiable,
analyzable subset of the Intel 8080 \ac{isa}.
Their work used \ac{spade}, a set of software tools for ``the efficient development,
analysis, and formal verification of high-integrity software''.
\Ac{spade} provides \iac{fdl} for modeling programs
in order to analyze and formally verify them
using \iac{vcg}, proof checker, and symbolic interpreter.
They used automatic translation to model their SPACE-8080 program
in \ac{fdl}, and their verification methodology used the same kind of
annotated control-flow analysis as our control-flow-driven approach
presented in \cref{ch:cfg} does, with additional assertions on state to avoid errors
and stronger conditions in order to prove functinoa correctness.
They also provided \emph{rewrite rules} that described the semantics
of the formal models in \ac{spade}. Unlike the work detailed in \cref{ch:cfg}, however,
they only covered a single 33-instruction function
with the verification methodology they presented.

Another usage of \ac{spade} for a more in-depth verification of assembly
was in the correctness proof of fuel control code for a Rolls-Royce
jet engine \autocite{oneill1988verification}. Once again,
it involved formulating a verification-friendly model of the Z8002 \ac{isa}
in \ac{spade}, the development of a Prolog translator from Z8002 assembly to \ac{fdl},
and the formalization of written specifications into proper pre- and postconditions
in \ac{spade}. \Ac{spade}'s proof checker was then used to validate the correctness
of the translated control code. While they assumedly covered many more instructions
than the previous \ac{spade} work did, the authors did not go into detail
on the amount of work that was actually done.
The only number given was that the specifications for about \SI{10}{\percent}
of the code modules under test were clarified
and one module received a code fix to improve its performance.

Similarly, Yu and Boyer \autocite{yu1993automated,boyer1996automated}
presented operational semantics and mechanized reasoning
for approximately \SI{80}{\percent} of the instructions of the MC68020 microprocessor,
over 85.
They implemented those semantics and mechanized their approach
in \ac{nqthm}, a precursor to the theorem prover ACL2 \autocite{ACL2}.
They then applied their mechanized reasoning to check functional correctness
for a binary search, quicksort, a standard C string library, and others.
These early efforts required significant interaction,
as Yu and Boyer required over \num{19000}
lines of manually written proof to verify approximately \num{900} assembly instructions.
Compare this to the \num{1047} lines of manual proof
required to prove memory preservation over \num{12252} assembly instructions.
Admittedly, they were verifying stronger properties,
which would greatly increase the amount of work required for verification,
but even then it's a significant difference.

Following that, \textcite{matthews2006verification}
targeted a simple machine model called TINY
as well as the M5 operational model of \ac{jvm} bitcode.
Their approach for functional correctness, implemented in ACL2,
utilized symbolic execution of operational semantics
over code annotated with manually written invariants
in order to generate \acp{vc} and then discharge them.
They even supported compositionality by verifying subcalls individually.
Both of the assembly-style languages they tested with feature a stack
for handling scratch variables rather than a register file
as x86, ARM, and most other mainstream \acp{isa} do.
The case studies they verified were an implementation of the Fibonacci sequence,
a factorial function, and functions for CBC-mode encryption and decryption.
In total, they covered \num{631} assembly instructions,
less than that handled by either of the methodologies presented in this dissertation.
Of course, they were targeting a stronger property than either of those works,
but they also did not perform any significant work to automate their approach.
All in all, however, this work is the closest to the control-flow-driven approach
presented in \cref{ch:cfg} of any of the works presented in this chapter,
as they even implemented a version in Isabelle. Their Isabelle version did not support
compositionality, however.

Additionally, Goel et al.\ presented an approach for modeling and verifying
non-deterministic programs on the binary level \autocite{goel2014syscalls,goelphd}.
As with \textcite{matthews2006verification}, their work was implemented in ACL2.
In addition to formulating the semantics of most user-mode x86 instructions,
they provided semantics for common system calls.
System call semantics increase the spread of programs that can be fully verified.
Their work was applied to multiple small case studies,
including a word count program and two kernel-mode memory copying examples.
 
Ultimately, the main difference between the above-mentioned existing approaches
and the methodologies presented in this dissertation lies in the degree of automation.
Interactive theorem proving over semantics of assembly instructions
does not scale under normal circumstances
due to the amount of intricate user interaction required.

Fully automated approaches to formal verification, however,
do not necessarily scale either.
The recent automated approach AUSPICE provided by \textcite{tan2015auspice}
takes about 6 hours to run on a 533-instruction string search algorithm.
This is despite the fact that, similar to our approaches, % todo: this sounds weird
they were targeting weaker safety properties
rather than going for functional correctness.
As another similarity to our approach in \cref{ch:syntax},
they too used a full set of Hoare rules in their analysis.
% todo: check the Hoare rules thing?

Though it is not a verification methodology by itself,
there is also \ac{dil}.
Developed by Myreen et al.\ in the HOL4 theorem prover \autocite{slind2008brief},
\ac{dil} uses operational semantics of machine code
to lift programs into a functional form.
That functional form can then be used in a Hoare logic framework
for program analysis \autocite{myreen2007hoare}.
It formally covers the gap between machine code and \iac{hol} model
and allows for verification of properties in a theorem prover that utilizes that model.
\Ac{dil} has been used for both ARM and x86 \ac{isa} machine models
and applied to various large examples,
including benchmarks such as a garbage collector as well as the Skein hash function.
It has even been used as a component in a binary-level verification methodology
over the seL4 microkernel \autocite{sewell2013tvv}.

Also, \textcite{feng2006modular,feng2005sbca} presented stack abstractions
for modular verification of assembly code
in the Coq theorem prover \autocite{chlipala2013certified}.
Their work allows for integration
of various proof-carrying code systems \autocite{necula1997proof}.
As with the work presented in \cref{ch:syntax},
it utilizes a Hoare-style framework for its verification.
The authors applied their work to multiple example functions,
such as two factorial implementations
as well as \lstinline[style=C]|setjmp| and \lstinline[style=C]|longjmp|.
In contrast to the approach presented in \cref{ch:syntax},
though not that in \cref{ch:cfg},
manual annotations are required to provide information
regarding invariants and memory layout.

\Textcite{schlich2008phd} worked on the development of a model checker for analysis
of microcontroller assembly, \mcsquare.
Implemented in Java and supporting several microcontroller \acp{isa},
it uses multiple methods of state space reduction in order to avoid state space explosion
as much as possible. While it was applied to multiple case studies,
some of those case studies were only to analyze the effectiveness
of the various abstraction techniques used for state space reduction.

The most relevant case study to this dissertation was its application
to software compiled for an automotive microcontroller \autocite{schlich2007automotive}.
The three programs they focused on for their case study
were designed to record speed measurements from sensors on four wheels,
calculate the actual speed, and then transmit it over \iac{can} bus.\footnote{%
  \Iac{can} bus is a standard bus for electronic communications
  in automotive applications.%
}
Some of the programs required simplification to be checkable,
so for consistency they applied, or at least attempted to apply,
the same simplifications to all three programs.
They did what they could to remove sends over the \ac{can} bus
and tried to focus on the speed signal from just one wheel rather than all four.
Ultimately, they were able to reason about all three programs
and prove both functional and non-functional properties of those programs.
On average they covered around 700 lines of C or \num{2666} assembly instructions.
In terms of the works presented in this dissertation,
the case study on HermitCore in \cref{se:cfg_application}
did involve isolating the functions under test before compiling them
and covered less instructions.
By contrast, the analyzed Xen functions in \cref{se:xen} were handled
without any modification whatsoever to the Xen build process
and covered even more instructions.

\Textcite{brauer2009sba} intially performed static analysis of stack bounds
for the Atmel ATmega16 and Intel MCS-51 microcontrollers
in order to verify a lack of stack overflows.
Their work was applied to eight programs, four compiled for each microcontroller.
The functions compiled for the ATmega16 \ac{isa}
had previously been used to evaluate the effectiveness of \mcsquare.
They then embedded their static analysis in \mcsquare\ as a means to
improve the accuracy of \ac{dvr}, which \mcsquare\ uses for state space reduction.
While this stack safety approach is similar in focus to the memory preservation works
I present here, the scope is much smaller.
Their focus was specifically on stack memory rather than memory in general.

Earlier this year, \textcite{fromherz2019verified} embedded a subset
of the \arch\ \ac{isa} in the functional, verification-oriented language
F$^*$ \autocite{fstar}.
This was done in order to prove commonly-used crytographic routines
that mix C with assembly for performance reasons are secure from information leakage.
The cryptographic routines they applied their work to were
Poly1305-\ac{aes} \autocite{bernstein2005poly1305} and
\ac{aes}-\ac{gcm} \autocite{dworkin2007recommendation}.
Their aim was to use F$^*$'s dependent type system to run a verified \ac{vcg}
during type checking, with the generated \acp{vc}
then being supplied to \iac{smt} solver.
The conditions on state to generate the \acp{vc} were expressed using Vale,
a language for assembly verification \autocite{bond2017vale}.
This was done in the style of \emph{proof by reflection} \autocite{bertot2004reflection}.
The \ac{vcg} itself, QuickCode, was formally proven sound in F$^*$ as well.
They measured performance of their verified algorithms, as one of them could be
transpiled to C. They also measured the performance of various versions
of their \ac{vcg}, and found that optimizing the \ac{smt} queries did improve performance
significantly.

Unlike our works in \cref{ch:cfg,ch:syntax}, the authors of this paper
had to do extra reasoning to ensure the C and assembly code models were interoperable.
As we operated directly on full assembly, we did not have to worry about
that kind of interfacing. Both this work and the work presented in \cref{ch:syntax} used an explicit \ac{vcg},
but ours was proven correct by its Isabelle/HOL definitions;
we did not have to perform any additional work to ensure correctness
of the methodology.
Of course, as we implemented ours in an interactive theorem prover,
we could guide the \ac{vc} generation and discharging as needed.

\section{Hardware Verification}\label{se:hardware}
On a level lower than the assembly code level, or even the machine code level,
is the work done by hardware designers and testers
to verify the products that run those codes.
Quite often this is done with model checkers.

For example, ARM recently released several of their \acp{isa} in a machine-parsable,
executable format called \ac{asl}, a result that took five years to develop.
While not directly verifiable, the documents were automatically translated into
a verifiable form for use with a verification tool
called ISA-Formal \autocite{reid2016endtoend}.
ISA-Formal is intended to verify processor pipeline control
and has been successfully used for that purpose on multiple versions of the ARM \ac{isa}.
At its core, it uses bounded model checking for instruction sequence exploration.
They accomplished this by developing a translator from \ac{asl}
to the subset of System-Verilog that can be handled by commercial Verilog model checkers.

Not all of the components they worked with could be handled by the model checkers,
however; they restricted its usage to \ac{isa} analysis.
Alternative verification techniques were used for the components that the model checkers
could not handle, such as the \acp{fpu} and memory system.
These alternative techniques involved raising the abstraction level
and/or reducing the explored state space,
as their goal was not necessarily to detect all bugs in those specific units.
Instead, they wanted to check the correctness of the logic connecting them
to other processor elements, which they were successful at.

More recently, the Sail \ac{isa} specification language,
which supports automatic generation of emulation code
and of proof definitions for Isabelle, HOL4, and in some cases Coq,
has been used to provide rigorous semantic models of various \ac{risc} \acp{isa}
\autocite{armstrong2018models,armstrong2019isa}.
The \acp{isa} in question are ARMv8.3-A, CHERI-MIPS, and RISC-V.
It was also used to produce a proof of correctness for a model of
ARMv8-A address translation in Isabelle.

\section{Integrated Assembly-Level Verification Efforts}\label{se:integrated_assembly}
A major verification effort based on \acl{dil}
was the verification of the seL4 kernel \autocite{klein2009sel4,Klein_AEMSKH_14}.
The seL4 project provides a microkernel written in formally proven correct C code.
The tool AutoCorres is used for C code verification \autocite{greenaway2012bridging}.
\textcite{sewell2013tvv} verified a \emph{refinement relation} between the C source code
and corresponding non-optimized and \lstinline|O2|-optimized ARM binaries.
The major differences with respect to our work
is that our methodology targets existing production code,
instead of code written with verification in mind.
For example, the seL4 source code does not allow taking the addresses of stack variables
(such as in \cref{fig:example2-c}):
their approach requires a static separation of stack and heap instead.

\textcite{shi2012orientais} formally verified \iac{rtos} for automotive use
called ORIENTAIS.
Part of their approach involved source-level verification
using a combination of Hoare logic
and abstract \ac{csp} model analysis \autocite{hoare1978csp}.
Binary verification was done by lifting the \ac{rtos} binary to xBIL,
a related hardware verification language \autocite{shi2012xbil}.
They translated requirements from the OSEK automotive industry standard
to source code annotations.
Ultimately, they proved properties such as deadlock-freedom, memory access safety,
and bounded response time in the presence of interrupts \autocite{shi2012interrupt}.
A similarity with our work was the usage of Hoare logic,
while the difference is that we performed verification solely on the assembly level
and with a more complex \ac{isa}.
We ultimately handled over \num{14631} \arch\ instructions compared to their \num{60}.
While they did handle \num{8000} lines of C as well,
that is still a higher-level language than \arch\ assembly.

Targeting a similar case study as \cref{ch:syntax},
\textcite{dam2013hypervisor,dam2013formal}
formally verified a tiny ARMv7 \emph{separation kernel},%
\index{separation kernel}
PROSPER, at the assembly level.
Separation kernels are similar to hypervisors,
providing isolation for individual components of a system and ensuring
only those components that are allowed to communicate do \autocite{rushby1981dvss}.
Their methodology integrated HOL4 with \ac{bap}.
\Ac{bap} utilizes a custom intermediate language
that provides an architecture-agnostic representation of machine instructions
and their side effects.
First, the formal model of the ARM \ac{isa} provided by \textcite{fox2010arm} was used
in an HOL4 tool to translate the ARM binary into \ac{bap}'s intermediate language.
Following that, the \ac{smt} solver \ac{stp}  \autocite{ganesh2007stp}
was used to determine the targets of indirect branches
and to perform weakest-precondition computation with Hoare triples
to verify the user contracts.
While the approach was generally automated,
user input was still required to describe the contracts
the separation kernel was verified against.
An extension to the work is found in the HAPSOC project by \textcite{baumann2016high},
who did a similar proof for the ARMv8-A model provided by \textcite{fox2015improved}.

Finally, \textcite{bevier1989approach} presented a systems approach
to software verification that targeted correctness
all the way down to the hardware level.
All of their work was implemented in \ac{nqthm}.
\Textcite{hunt1989microprocessor} developed a general-purpose, 32-bit microprocessor,
FM8502, and proved that its gate-level specification
was an implementation of its formal \ac{isa}.
\Textcite{bevier1989short,bevier1989kit,bevier1987verified}
designed a small \ac{os} kernel, Kit, and proved that it implemented
``a fixed number of conceptually distributed communicating processes''
along with a set of typical kernel services and some security properties.
He did not prove that it could run on an FM8502, however;
it was executed on a more abstract model instead.
\Textcite{young1989generator} designed and proved the correctness of a code generator,
a major compiler component, for a subset of the Gypsy 2.05 programming language
\autocite{good1986gypsy}. That code generator's output was
the verified, high-level assembly language Piton \autocite{moore1988piton}.
\Textcite{moore1989language} then proved the correctness
of that language's FM8502 implementation.

\section{Verified Compilation}\label{se:verified}
In contrast to directly verifying machine or assembly code,
one can verify source code and then use \emph{verified compilation}.%
\index{verified compilation}
Verified compilation establishes that
the semantics of the output of the verified compiler
is equivalent to the semantics of the input,
so a program that has previously been verified correct
is verified to still be correct after compilation.

The CompCert project is one such verified compiler,
used by the seL4 project to reduce its \ac{tcb} \autocite{Klein_AEMSKH_14}.
It is written in a subset of C
called Clight \autocite{leroy:compcert,blazy2009clight},
though it itself is able to handle most components of the C99 standard.
The main difference between C and Clight is that Clight is \emph{pure};
none of its operations have side effects. It also provides only one loop structure,
an infinite loop that must be broken out of to exit.
Clight has been mechanized in the Coq theorem prover with established
big-step operational semantics, making it a useful subset of C
for program verification work in Coq.

The full proof of \emph{semantic preservation},
as it is called in the CompCert documentation,
is based off of proofs of semantic preservation
for each step in CompCert's compilation process, of which there are twenty.
On top of that, it has eleven different intermediate languages for those steps,
all of which had to be proven semantically equivalent.

Another example of verified compilation is CakeML \autocite{kumar2014cakeml}.
It utilizes a (substantial)
subset of Standard ML modeled with big-step operational semantics in \ac{hol}.
Its main compiler frontend is designed to take ML-like \ac{hol} functions
and translate them to a CakeML \ac{ast}, which is then translated into machine code
using a verified backend. The compiler itself is bootstrapped,
meaning it can compile itself in \ac{hol}. It also provides support for using Hoare logic
to perform post-hoc verification using a version of the CFML verification framework
\autocite{gueneau2017formulae,arthur2015union,chargueraud2011cfv}.

More recently, \textcite{chen2018compositional} produced a compositional framework
for the development of certified, \emph{interruptible}%
\index{interrupt}
\ac{os} kernels that use device drivers.%
\index{operating system!kernel}
This was previously a challenge due to the non-local and asynchronous behavior
of hardware interrupts. Their approach uses a general certified device model
with multiple instantiations and provides an effective model of device interrupts.
The verification was done in Coq with the kernel written in Clight.
Once verification was complete, the source code was compiled using a modified version
of CompCert to ensure the semantics were maintained.
They showed the value of their work by taking a preexisting,
non-interruptible, mostly-verified kernel, mCertiKOS \autocite{costanzo2016endtoend},
and extending it to work in their framework along with a couple of device drivers.
In order to deal with devices running in parallel with the \ac{cpu},
device interaction, drivers that are written in a mix of assembly and C,
and properly integrating the correctness proofs for individual components
of the system under test, they did the following.
First, they designed their system architecture such that each device driver
is given its own logical \ac{cpu}, running independently from the core of the kernel.
Then they designed an abstract model of interrupts
based on existing hardware implementations.
The correctness of the system as a whole was shown
by starting from a base machine model
and proving a refinement relation with each layer of abstraction placed on top of it.
As they started off with a mostly-verified kernel, it is likely they would have had
more difficulty if they had started with a kernel
not explicitly designed to be verified. While we did isolate functions
for verification in \cref{ch:cfg}, we did not do so for \cref{ch:syntax}.

\section{Non-Formal Static Analysis}\label{se:static_analysis}
Non-formal static analysis of binary code for the detection of bugs
has also been an active research field for decades
\autocite{kruegel2005automating,brumley2011bap,wang2017angr}.
This section covers some of the projects in that field from the past fifteen years.

The BitBlaze project \autocite{song2008bitblaze,BitBlazeWebSite}
provides a tool called Vine which lifts x86 instructions to its own \ac{il} for assembly
in order to perform analyses on a higher level.
That language is fully-featured and can itself be compiled back down to assembly
if so desired.
In terms of analyses, Vine can construct \acp{cfg} for the lifted programs,
perform compiler-style dataflow analysis, generate dependency graphs,
and slice programs \autocite{weiser1981slicing,tip1995survey}.
Though Vine itself is not formally verified,
it does support interfacing with the aforementioned \ac{smt} solver \ac{stp}
as well as CVC Lite \autocite{barrett2004cvcl} and CVC3 \autocite{barrett2007cvc3}.
This allows for formal verification.

Meanwhile, the tool Infer \autocite{calcagno2011infer}, now developed at Facebook,
provides in-depth static analysis of LLVM code to detect bugs in programs
written in a variety of languages.
It utilizes separation logic \autocite{reynolds2002separation}
and bi-abduction to perform its analyses in an automated fashion.
It is designed to be integrated into compiler toolchains
in order to provide immediate feedback even in \ac{ci} scenarios.
For all the languages it handles, it checks for null pointer accesses
and other null-related issues as well as checking for language-specific
concurrency issues.
For C-style languages with a lower level of abstraction,
it also looks for memory leaks, performs linting for violations of coding conventions,
and checks for calls to mobile device \acp{api} that are not available
for the target device \ac{os}.
In Android code and Java in general, it ensures annotations can be reached,
looks out for mutability issues, and checks for resource leaks.

The static analysis tool FindBugs, written for Java code,
takes a bit of a different approach from those other two
\autocite{hovemeyer2004findbugs}.
Rather than performing control flow or dataflow analyses,
it searches Java bytecode for common (bad practice) code idioms
in order to detect likely bugs. Much like Infer,
some of the common errors it highlights include null pointer dereferences,
objects that compare equal not having equal hash codes,
and inconsistent synchronization.
It even provides a bug database that can be used to keep track of its warnings
throughout multiple iterations of development.

A somewhat older tool, Splint \autocite{evans2002static} detects buffer overflows
and similar potential security flaws in C code.
Splint relies on annotated preconditions to derive postconditions
based on the syntactic structure of the code.
While their methodology is very similar to the formal technique of Hoare logic,
described later on in this dissertation (\cref{se:hoare}),
they used heuristics for loop analysis rather than proper invariants
and thus could potentially miss bugs.
The annotations Splint uses are memory-focused, such as allowing users to specify
that certain variables should never be null or providing an emulation of
\lstinline|unique_ptr| functionality. It also does constraint analysis
and issues warnings when it encounters an expression it cannot determine
will not result in a bug, as well as checking for format string vulnerabilities.

The main difference between these static analysis tools and formal verification
is that these tools are generally highly suited to finding bugs
but are not able to prove their absence. This is due to a reliance on 
efficient but incomplete techniques, such as depth-bounded searches.

\begin{table*}
  \centering
  \caption{Overview of related assembly verification and other work}\label{related-table}
  \begin{tabular}{l l l l l}
    \toprule
    \thead{Work} & \thead{Target} & \thead{Approach} & \thead{Applications} & \thead{Verified code} \\
    \midrule
    Clutterbuck\&Carr\'e & SPACE-8080 & \acs*{itp}+\acs*{vcg} & Example func & \num{33} insts \\
    O'Neill et al. & Z8002 & \acs*{itp}+\acs*{vcg} & Jet engine code & \\
    Yu \& Boyer & MC68020 & \acs*{itp} & String funcs & \num{863} insts \\
    Matthews et al. & Tiny/JVM & \acs*{itp}+\acs*{vcg} & CBC enc/dec & \num{631} insts \\
    Goel et al. & \arch & \acs*{itp} & word-count  & \num{186} insts \\
    Tan et al. & ARMv7 & ATP & String search & \num{983} insts \\
    Myreen et al. & ARM/x86 & \acs*{dil} & seL4 & \num{9500} \acs*{sloc} \\
    Feng et al. & MIPS-like & \acs*{itp} & Example funcs & \\
    Schlich et al. & ATmega16 & MC & Auto funcs & Around \num{8000} insts \\
    Brauer et al. & \makecell[l]{ATmega16\\Intel MCS-51} & SA+MC & Example progs &
      \makecell[l]{\num{2630} \acs*{sloc}\\
        \num{935} \acs*{sloc}} \\
    Fromherz et al. & C/\arch & ATP+\acs*{vcg} & \acs{aes} funcs & \\
    \textbf{\cref{ch:cfg}} & \arch & \acs*{itp}+\acs{vcg} & HermitCore & \num{2379}+ insts \\
    \textbf{\cref{ch:syntax}} & \arch & CG+\acs*{itp}+\acs{vcg} & Xen & \num{12252} insts \\
    \midrule
    Reid et al. & \acs*{asl} & MC+others & ARM \acp{isa} & \num{2209191}+ \acs*{sloc} \\
    Sewell et al. & C & \acs*{tv}+\acs*{dil} & seL4 & \num{9500} \acs*{sloc} \\
    Shi et al. & C/ARM9 & \acs*{atp}+\acs*{mc} & ORIENTAIS & \num{8000} \acs*{sloc}, 60 insts \\
    Dam et al. & ARMv7 & \acs*{atp}+UC & PROSPER & \num{3000} insts \\
    Baumann et al. & ARMv8-A & \acs*{atp}+UC & HAPSOC & \num{8000} \acs*{sloc} \\
    Bevier et al. & PDP-11-like & \acs*{itp}+TV & Full system & \num{3000}+ \acs*{sloc}/insts \\
    \bottomrule
    \multicolumn{5}{c}{
      \small
      \newlength\colseplen
      \setlength\colseplen{1ex}
      \newcommand\colsep{\hspace\colseplen}
      \begin{tabular}{l@{\colsep}c@{\colsep}l l@{\colsep}c@{\colsep}l}
        \acs*{vcg} &=& Verification Condition Generation & \acs*{dil} &=& Decompilation into Logic \\
        \acs{sloc} &=& Source Lines of Code        & \acs*{atp} &=& Automated Theorem Proving \\
        UC   &=& User Contracts											& CG 	&=& Certificate Generation \\
        TV   &=& Translation Validation							& MC 	&=& Model Checking \\
        SA   &=& Static Analysis                    & \acs*{asl} &=& \acl*{asl}
      \end{tabular}
    }
  \end{tabular}
\end{table*}

\section{Summary}
This section covered some of the work related to that presented in this dissertation.
Previous assembly- and hardware-level formal verification efforts,
verification efforts containing assembly or binary analysis components,
verified compilation, and non-formal static analysis tools were all discussed.

Notably, while multiple assembly-level verification efforts
presented in this chapter achieved more coverage
than the over \num{2379} instructions achieved by the work in \cref{ch:cfg},
none appear to have achieved the \num{12252}
verified instructions covered in \cref{ch:syntax} except the work produced by
ARM employees.
