\chapter{Related Work}
% TODO: Flesh out to get up to eight pages?

Verification of assembly has been an active research field for decades.
\Cref{related-table} provides an inexhaustive overview of related work,
discussed in the following sections.
Up first in \cref{se:previous_assembly}
are some previous formal verification efforts that target assembly.
Following that is work in which assembly verification played a role
in a larger verification context, \cref{se:integrated_assembly}.
Finally, verified compilation and static analysis tools are discussed
in \cref{se:verified,se:static_analysis}.

\section{Previous Approaches to Assembly Verification}\label{se:previous_assembly}
\citet{clutterbuck1988verification} performed formal verification
of assembly code using SPACE-8080, a verifiable subset of the Intel 8080
\ac{isa} that is analyzable and formally verifiable~\citep{carre1986spade}.
% Their approach uses Floyd-style verification~\cite{floyd1967assigning}.
Another usage of \ac{spade} for verification of assembly
was in the correctness proof of fuel control code for a Rolls-Royce
jet engine~\citet{oneill1988verification}.

Not long after, Bevier et al.\ presented a systems approach
to software verification~\citep{bevier1989approach,boyer1979computational}.
Their work laid out a methodology for verifying the correctness
of all components necessary to execute a program correctly,
including compiler, assembler and linker.
It was implemented in \ac{nqthm}~\citep{boyer1979computational},
a precursor to the theorem prover ACL2~\citep{ACL2}.
The methodology was applied to a small \ac{os} kernel, Kit~\citep{bevier1989kit}.

Similarly, Yu and Boyer~\citep{yu1992automated,boyer1996automated}
presented operational semantics and mechanized reasoning
for approximately 80\% of the instructions of the MC68020 microprocessor,
over 85.
Their approach utilized symbolic execution of operational semantics.
These early efforts required significant interaction.
For example, the approach of Yu and Boyer required over \num{19000}
lines of manually written proof to verify approximately \num{900} assembly instructions.

Following that, \citet{matthews2006verification}
targeted a simple machine model called TINY
as well as the M5 operational model of \ac{jvm} bitcode.
Their approach utilizes symbolic execution of code annotated
with manually written invariants.
It also used verification condition generation to increase automation,
which reduced the number of manually written invariants.
Both of those assembly-style languages feature a stack
for handling scratch variables rather than a register file
as x86, ARM, and most other mainstream \acp{isa} do.

Additionally, Goel et al.\ presented an approach for modeling and verifying
non-deterministic programs on the binary level~\citep{goel2014syscalls,goelphd}.
As with \citet{matthews2006verification}, their work was implemented in ACL2.
In addition to formulating the semantics of most user-mode x86 instructions,
they provided semantics for common system calls.
System call semantics increase the spread of programs that can be fully verified.
Their work was applied to multiple small case studies,
including a word count program and two kernel-mode memory copying examples.

\begin{table*}
  \centering
  \caption{Overview of Related Work.}\label{related-table}
  \begin{tabular}{l l l l l}
    \toprule
    Work & Target & Approach & Applications & Verified code\\
    \midrule
    Clutterbuck \& Carr\'e & SPACE-8080 & \acs*{itp} & N/A & \\
    Bevier et al. & PDP-11-like & \acs*{itp} & Kit & \\
    Yu \& Boyer & MC68020 & \acs*{itp} & String funcs & \num{863} insts \\
    Matthews et al. & Tiny/JVM & \acs*{itp}+\acs*{vcg} & CBC enc/dec & \num{631} insts \\
    Goel et al. & x86-64 & \acs*{itp} & word-count  & \num{186} insts \\
    Tan et al. & ARMv7 & ATP & String search & \num{983} insts \\
    Myreen et al. & ARM/x86 & \acs*{dil} & seL4 & \num{9500} \acs*{sloc} \\
    Feng et al. & MIPS-like & \acs*{itp} & Example funcs & \\
    This paper & x86-64 & \ac*{itp}+CG & Xen & \num{12252} insts \\
    \midrule
    Sewell et al. & C & \acs*{tv}+\acs*{dil} & seL4 & \num{9500} \acs*{sloc} \\
    Shi et al. & C/ARM9 & \acs*{atp}+\acs*{mc} & ORIENTAIS & \num{8000} \acs*{sloc}, 60 insts \\
    Dam et al. & ARMv7 & \acs*{atp}+UC & PROSPER & \num{3000} insts \\
    Baumann et al. & ARMv8-A & \acs*{atp}+UC & HAPSOC & \num{8000} \acs*{sloc} \\
    \bottomrule
    \multicolumn{5}{c}{
      \small
      \newlength\colseplen
      \setlength\colseplen{1ex}
      \newcommand\colsep{\hspace\colseplen}
      \begin{tabular}{l@{\colsep}c@{\colsep}l l@{\colsep}c@{\colsep}l}
        VCG  &=& Verification Condition Generation	& \acs*{dil} &=& Decompilation into Logic \\
        \acs*{sloc} &=& Source Lines of Code        & ATP &=& Automated Theorem Proving \\
        UC   &=& User Contracts											& CG 	&=& Certificate Generation \\
        TV   &=& Translation Validation							& MC 	&=& Model Checking
      \end{tabular}
    }
  \end{tabular}
\end{table*}

The main difference between the above-mentioned existing approaches
and the methodologies presented in this work is in the degree of automation.
Generally, interactive theorem proving over semantics of assembly instructions
does not scale due to the amount of intricate user interaction involved.
For example, \cref{fig:example2-inv} shows
the complexity of defining an assembly-level invariant even for a small example.
Fully automated approaches to formal verification, however, do not scale either.
The recent automated approach AUSPICE provided by \citet{tan2015auspice}
takes about 6 hours for a 533-instruction string search algorithm.
To the best of my knowledge,
the methodologies presented here are the first that are able to deal with
optimized x86-64 binaries produced by production code
with a ``manual effort vs.\ instruction count ratio'' of roughly 1 to 11,
at least for the work presented in \cref{ch:syntax}.

Though it is not a verification methodology by itself,
there is also \emph{\ac{dil}}~%
\citep{myreen2008decompilation,myreen2012decompilation}.
Developed by Myreen et al.\ in the HOL4 theorem prover~\citep{slind2008brief},
\ac{dil} uses operational semantics of machine code
to lift programs into a functional form.
That functional form can then be used in a Hoare logic framework
for program analysis~\citep{myreen2007hoare}.
It formally covers the gap between machine code and \iac{hol} model
and allows for verification of properties in a theorem prover that utilizes that model.
\Ac{dil} has been used for both ARM and x86 \ac{isa} machine models
and applied to various large examples,
including benchmarks such as a garbage collector as well as the Skein hash function.
It has also has been used as a component in a binary-level verification methodology~\citep{sewell2013tvv}.

Finally, \citet{feng2006modular,feng2005sbca} presented stack abstractions
for modular verification of assembly code
in the Coq theorem prover~\citep{chlipala2013certified}.
Their work allows for integration
of various proof-carrying code systems~\citep{necula1997proof}.
As with the work presented in \cref{ch:syntax},
it utilizes a Hoare-style framework for its verification.
The authors applied their work to multiple example functions,
such as two factorial implementations
as well as \lstinline[style=C]|setjmp| and \lstinline[style=C]|longjmp|.
In contrast to the approach presented in \cref{ch:syntax},
though not that in \cref{ch:cfg},
manual annotations are required to provide information
regarding invariants and memory layout.

\section{Integrated Assembly-Level Verification Efforts}\label{se:integrated_assembly}
A major verification effort, based on decompilation-into-logic,
was the verification of the seL4 kernel~\citep{klein2009sel4,Klein_AEMSKH_14}.
The seL4 project provides a microkernel written in formally proven correct C code.
The tool AutoCorres~\citep{greenaway2012bridging} is used for C code verification.
\citet{sewell2013tvv} verified a refinement relation between the C source code
and an ARM binary for both non-optimized and optimized at \lstinline{O2}.
The major differences with respect to our work
is that our methodology targets existing production code,
instead of code written with verification in mind.
For example, the seL4 source code does not allow taking the addresses of stack variables
(such as in \cref{fig:example2-c}):
their approach requires a static separation of stack and heap instead.
Neither the seL4 proof effort nor any of the methodologies presented here
support function pointers.

\citet{shi2012orientais} formally verified \iac{rtos} for automotive use
called ORIENTAIS.
Part of their approach involved source-level verification
using a combination of Hoare logic
and abstract \ac{csp} model analysis~\citep{hoare1978csp}.
Binary verification was done by lifting the \ac{rtos} binary to xBIL,
a related hardware verification language~\citep{shi2012xbil}.
They translated requirements from the OSEK automotive industry standard
to source code annotations.

Targeting a similar case study as \cref{ch:syntax},
\citet{dam2013hypervisor,dam2013formal}
formally verified a tiny ARMv7 \emph{separation kernel},%
\index{separation kernel}
PROSPER, at the assembly level.
Separation kernels are similar to hypervisors,
providing isolation for individual components of a system and ensuring
only those components that are allowed to communicate do~\citep{rushby1981dvss}.
Their methodology integrated HOL4 with the \ac{bap}~\citep{brumley2011bap}.
\Ac{bap} utilizes a custom intermediate language
that provides an architecture-agnostic representation of machine instructions
and their side effects.
First, the formal model of the ARM \ac{isa} provided by \citet{fox2010arm} was used
in an HOL4 tool to translate the ARM binary into \ac{bap}'s intermediate language.
Following that, the \ac{smt} solver \ac{stp}~\citep{ganesh2007stp}
was used to determine the targets of indirect branches
and to perform weakest-precondition computation with Hoare triples
to verify the user contracts.
While the approach was generally automated,
user input was still required to describe the contracts
the separation kernel was verified against.
An extension to the work is found in the HAPSOC project by \citet{baumann2016high},
who did a similar proof for the ARMv8-A model provided by \citet{fox2015improved}.

\section{Verified Compilation}\label{se:verified}
In contrast to directly verifying machine or assembly code,
one can verify source code and then use \emph{verified compilation}.%
\index{verified compilation}
Verified compilation establishes that the semantics of the output of the verified compiler
is equivalent to the semantics of the input. This is done via refinement relations.
The CompCert project~\citep{leroy:compcert} provides a compiler for a subset of C.
Its output has been verified to have the same semantics as the C source code.
The seL4 project used CompCert to reduce its \ac{tcb}~\citep{Klein_AEMSKH_14}.
Another example of verified compilation is CakeML~\citep{kumar2014cakeml}.
It utilizes a subset of Standard ML modeled with big-step operational semantics.
The main purpose of verified compilation, however,
is not to verify properties over the code.
For example, if the source code is vulnerable to \iac{rop} exploit,
then the assembly code is vulnerable as well.
Verified compilation is thus often accompanied by source code verification.
This dissertation argues that for memory usage, assembly-level verification is necessary.

\section{Static Analysis}\label{se:static_analysis}
Static analysis of binary code has also an active research field
for decades~\cite{kruegel2005automating,brumley2011bap,wang2017angr}.
The BitBlaze project~\citep{song2008bitblaze}
provides a tool called Vine which constructs control flow graphs
for supplied programs and lifts x86 instructions to its own \ac{il}.
Though Vine itself is not formally verified,
it does support interfacing with the aforementioned \ac{smt} solver \ac{stp}
as well as CVC~\citep{barrett2004cvcl,barrett2007cvc3}.
The tool Infer~\citep{calcagno2011infer}, developed at Facebook,
provides in-depth static analysis of LLVM code to detect bugs in C and C++ programs.
It utilizes separation logic~\citep{reynolds2002separation}
and bi-abduction to perform its analyses in an automated fashion.
It is designed to be integrated into compiler toolchains
in order to provide immediate feedback even in \ac{ci} scenarios.
FindBugs is a static analysis tool for Java code~\citep{hovemeyer2004findbugs}.
Rather than relying on formal methods,
it uses searches for common (bad practice) code idioms to detect likely bugs.
Common errors it highlights include null pointer dereferences,
objects that compare equal not having equal hash codes,
and inconsistent synchronization.
The tool Splint~\citep{evans2002static} detects buffer overflows
and similar potential security flaws in C code.
It relies on annotated preconditions to derive postconditions
based on the syntactic structure of the code.

The main difference between these static analysis tools and formal verification
is that these tools are generally highly suited to finding bugs
but are not able to prove their absence.
They generally apply techniques that are formally unsound, such as depth-bounded searches.

\section{Summary}
This section covered some of the work related to that presented in this dissertation.
Previous assembly- or lower-level formal verification efforts,
verification efforts containing assembly or binary analysis components,
verified compilation, and static analysis tools were all discussed.
