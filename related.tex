\chapter{Related Work}\label{ch:related}
Verification of assembly has been an active research field for decades.
\todo{more intro}

\Cref{related-table} provides an overview of related work,
discussed in the following sections.
Up first in \cref{se:previous_assembly}
are some previous formal verification efforts that target assembly.
Following that is work in which assembly verification played a role
in a larger verification context, \cref{se:integrated_assembly},
and then verified compilation and static analysis tools are discussed
in \cref{se:verified,se:static_analysis}.

\section{Assembly-Level Verification}\label{se:previous_assembly}
\textcite{clutterbuck1988verification} performed formal verification
of assembly programs using SPACE-8080, a verifiable,
analyzable subset of the Intel 8080 \ac{isa}.
Their work used \ac{spade}\autocite{carre1986spade},
a set of software tools for ``the efficient development,
analysis, and formal verification of high-integrity software''.
\Ac{spade} provides \iac{fdl} for modeling programs
in order to analyze and formally verify them
using \iac{vcg}, proof checker, and symbolic interpreter.
They used automatic translation to model their SPACE-8080 program
in \ac{fdl}, and their verification methodology used the same kind of
annotated control-flow analysis as our control-flow-driven approach
presented in \cref{ch:cfg} does, with additional assertions on state to avoid errors
and stronger conditions in order to prove functinoa correctness.
They also provided \emph{rewrite rules} that described the semantics
of the formal models in \ac{spade}. Unlike the work detailed in \cref{ch:cfg}, however,
they only covered a single 33-instruction function
with the verification methodology they presented.

Another usage of \ac{spade} for a more in-depth verification of assembly
was in the correctness proof of fuel control code for a Rolls-Royce
jet engine \autocite{oneill1988verification}. Once again,
it involved formulating a verification-friendly model of the Z8002 \ac{isa}
in \ac{spade}, the development of a Prolog translator from Z8002 assembly to \ac{fdl},
and the formalization of written specifications into proper pre- and postconditions
in \ac{spade}. \Ac{spade}'s proof checker was then used to validate the correctness
of the translated control code. While they assumedly covered many more instructions
than the previous \ac{spade} work did, the authors did not go into detail
on the amount of work that was actually done.
The only number given was that the specifications for about \SI{10}{\percent}
of the code modules under test were clarified
and one module received a code fix to improve its performance.

Similarly, Yu and Boyer \autocite{yu1993automated,boyer1996automated}
presented operational semantics and mechanized reasoning
for approximately \SI{80}{\percent} of the instructions of the MC68020 microprocessor,
over 85.
They implemented those semantics and mechanized their approach
in \ac{nqthm} \autocite{boyer1979computational},
a precursor to the theorem prover ACL2 \autocite{ACL2}.
They then applied their mechanized reasoning to check functional correctness
for a binary search, quicksort, a standard C string library, and others.
These early efforts required significant interaction,
as Yu and Boyer required over \num{19000}
lines of manually written proof to verify approximately \num{900} assembly instructions.
Compare this to the \num{1047} lines of manual proof
required to prove memory preservation over \num{12252} assembly instructions.
Admittedly, they were verifying stronger properties,
which would greatly increase the amount of work required for verification,
but even then it's a significant difference.

Following that, \textcite{matthews2006verification}
targeted a simple machine model called TINY
as well as the M5 operational model of \ac{jvm} bitcode.
Their approach for functional correctness, implemented in ACL2,
utilized symbolic execution of operational semantics
over code annotated with manually written invariants.
This is very much like the control-flow-driven approach presented in this dissertation.
It also used verification condition generation to increase automation,
which reduced the number of manually written invariants.
That was not done for the control-flow-driven verification.
Both of those assembly-style languages feature a stack
for handling scratch variables rather than a register file
as x86, ARM, and most other mainstream \acp{isa} do.
The case studies they verified were an implementation of the Fibonacci sequence,
a factorial function, and functions for CBC-mode encryption and decryption.
In total, they covered \num{631} assembly instructions,
less than that handled by either of the methodologies presented in this dissertation.
Once again, of course, they were targeting a stronger property,
but they also did not perform any significant work to automate their approach.

Additionally, Goel et al.\ presented an approach for modeling and verifying
non-deterministic programs on the binary level \autocite{goel2014syscalls,goelphd}.
As with \textcite{matthews2006verification}, their work was implemented in ACL2.
In addition to formulating the semantics of most user-mode x86 instructions,
they provided semantics for common system calls.
System call semantics increase the spread of programs that can be fully verified.
Their work was applied to multiple small case studies,
including a word count program and two kernel-mode memory copying examples.
 
Ultimately, the main difference between the above-mentioned existing approaches
and the methodologies presented in this dissertation lies in the degree of automation.
Interactive theorem proving over semantics of assembly instructions
does not scale under normal circumstances
due to the amount of intricate user interaction involved.

Fully automated approaches to formal verification, however, do not necessarily scale either.
The recent automated approach AUSPICE provided by \textcite{tan2015auspice}
takes about 6 hours to run on a 533-instruction string search algorithm.
This is despite the fact that they were targeting weaker safety properties
rather than going for functional correctness.
They even used a full formulation of Hoare logic, much as is done in \cref{ch:syntax}.

Though it is not a verification methodology by itself,
there is also \emph{\ac{dil}} \autocite{myreen2008decompilation,myreen2012decompilation}.
Developed by Myreen et al.\ in the HOL4 theorem prover \autocite{slind2008brief},
\ac{dil} uses operational semantics of machine code
to lift programs into a functional form.
That functional form can then be used in a Hoare logic framework
for program analysis \autocite{myreen2007hoare}.
It formally covers the gap between machine code and \iac{hol} model
and allows for verification of properties in a theorem prover that utilizes that model.
\Ac{dil} has been used for both ARM and x86 \ac{isa} machine models
and applied to various large examples,
including benchmarks such as a garbage collector as well as the Skein hash function.
It has even been used as a component
in a binary-level verification methodology over the seL4 microkernel \autocite{sewell2013tvv}.

Also, \textcite{feng2006modular,feng2005sbca} presented stack abstractions
for modular verification of assembly code
in the Coq theorem prover \autocite{chlipala2013certified}.
Their work allows for integration
of various proof-carrying code systems \autocite{necula1997proof}.
As with the work presented in \cref{ch:syntax},
it utilizes a Hoare-style framework for its verification.
The authors applied their work to multiple example functions,
such as two factorial implementations
as well as \lstinline[style=C]|setjmp| and \lstinline[style=C]|longjmp|.
In contrast to the approach presented in \cref{ch:syntax},
though not that in \cref{ch:cfg},
manual annotations are required to provide information
regarding invariants and memory layout.

\Textcite{schlich2008phd} worked on the development of a model checker for analysis
of microcontroller assembly, \mcsquare.
Implemented in Java and supporting several microcontroller \acp{isa},
it uses multiple methods of state space reduction in order to avoid state space explosion
as much as possible. While it was applied to multiple case studies,
some of those case studies were only to analyze the effectiveness
of the various abstraction techniques used for state space reduction.

The most relevant case study to this dissertation was its application
to software compiled for an automotive microcontroller \autocite{schlich2007automotive}.
The three programs they focused on for their case study
were designed to record speed measurements from sensors on four wheels,
calculate the actual speed, and then transmit it over \iac{can} bus.\footnote{%
  \Iac{can} bus is a standard bus for electronic communications in automotive applications.%
}
Some of the programs required simplification to be checkable,
so for consistency they applied, or at least attempted to apply,
the same simplifications to all three programs.
They did what they could to remove sends over the \ac{can} bus
and tried to focus on the speed signal from just one wheel rather than all four.
Ultimately, they were able to reason about all three programs
and prove both functional and non-functional properties of those programs.
On average they covered around 700 lines of C or \num{2666} assembly instructions.
In terms of the works presented in this dissertation,
the case study on HermitCore in \cref{se:cfg_application}
did involve isolating the functions under test before compiling them
and covered less instructions.
By contrast, the analyzed Xen functions in \cref{se:xen} were handled
without any modification whatsoever to the Xen build process
and covered even more instructions.

\Textcite{brauer2009sba} intially performed static analysis of stack bounds
for the Atmel ATmega16 and Intel MCS-51 microcontrollers
in order to verify a lack of stack overflows.
Their work was applied to eight programs, four compiled for each microcontroller.
The functions compiled for the ATmega16 \ac{isa}
had previously been used to evaluate the effectiveness of \mcsquare.
They then embedded their static analysis in \mcsquare\ as a means to
improve the accuracy of \ac{dvr}, which \mcsquare\ uses for state space reduction.
While this stack safety approach is similar in focus to the memory preservation works
I present here, the scope is much smaller.
Their focus was specifically on stack memory rather than memory in general.

\section{Integrated Assembly-Level Verification Efforts}\label{se:integrated_assembly}
A major verification effort based on \acl{dil}
was the verification of the seL4 kernel \autocite{klein2009sel4,Klein_AEMSKH_14}.
The seL4 project provides a microkernel written in formally proven correct C code.
The tool AutoCorres is used for C code verification \autocite{greenaway2012bridging}.
\textcite{sewell2013tvv} verified a \emph{refinement relation} between the C source code
and corresponding non-optimized and \lstinline|O2|-optimized ARM binaries.
The major differences with respect to our work
is that our methodology targets existing production code,
instead of code written with verification in mind.
For example, the seL4 source code does not allow taking the addresses of stack variables
(such as in \cref{fig:example2-c}):
their approach requires a static separation of stack and heap instead.
% seL4 actually does support function pointers, so I removed that sentence
\todo{more}

\textcite{shi2012orientais} formally verified \iac{rtos} for automotive use
called ORIENTAIS.
Part of their approach involved source-level verification
using a combination of Hoare logic
and abstract \ac{csp} model analysis \autocite{hoare1978csp}.
Binary verification was done by lifting the \ac{rtos} binary to xBIL,
a related hardware verification language \autocite{shi2012xbil}.
They translated requirements from the OSEK automotive industry standard
to source code annotations.

Targeting a similar case study as \cref{ch:syntax},
\textcite{dam2013hypervisor,dam2013formal}
formally verified a tiny ARMv7 \emph{separation kernel},%
\index{separation kernel}
PROSPER, at the assembly level.
Separation kernels are similar to hypervisors,
providing isolation for individual components of a system and ensuring
only those components that are allowed to communicate do \autocite{rushby1981dvss}.
Their methodology integrated HOL4 with the \ac{bap} \autocite{brumley2011bap}.
\Ac{bap} utilizes a custom intermediate language
that provides an architecture-agnostic representation of machine instructions
and their side effects.
First, the formal model of the ARM \ac{isa} provided by \textcite{fox2010arm} was used
in an HOL4 tool to translate the ARM binary into \ac{bap}'s intermediate language.
Following that, the \ac{smt} solver \ac{stp}  \autocite{ganesh2007stp}
was used to determine the targets of indirect branches
and to perform weakest-precondition computation with Hoare triples
to verify the user contracts.
While the approach was generally automated,
user input was still required to describe the contracts
the separation kernel was verified against.
An extension to the work is found in the HAPSOC project by \textcite{baumann2016high},
who did a similar proof for the ARMv8-A model provided by \textcite{fox2015improved}.

Finally, \textcite{bevier1989approach} presented a systems approach to software verification
that targeted correctness all the way down to the hardware level.
All of their work was implemented in \ac{nqthm}.
\Textcite{hunt1989microprocessor} developed a general-purpose, 32-bit microprocessor,
FM8502, and proved that its gate-level specification
was an implementation of its formal \ac{isa}.
\Textcite{bevier1989short,bevier1989kit,bevier1987verified}
designed a small \ac{os} kernel, Kit, and proved that it implemented
``a fixed number of conceptually distributed communicating processes''
along with a set of typical kernel services and some security properties.
He did not prove that it could run on an FM8502, however;
it was executed on a more abstract model instead.
\Textcite{young1989generator} designed and proved the correctness of a code generator,
a major compiler component, for a subset of the Gypsy 2.05 programming language
\autocite{good1986gypsy}. That code generator's output was
the verified, high-level assembly language Piton \autocite{moore1988piton}.
\Textcite{moore1989language} then proved the correctness
of that language's FM8502 implementation.

\section{Verified Compilation}\label{se:verified}
In contrast to directly verifying machine or assembly code,
one can verify source code and then use \emph{verified compilation}.%
\index{verified compilation}
Verified compilation establishes that
the semantics of the output of the verified compiler
is equivalent to the semantics of the input.
This can be done via refinement relations, but is not always.

The CompCert project is one such verified compiler,
used by the seL4 project to reduce its \ac{tcb} \autocite{Klein_AEMSKH_14}.
It is written in a subset of C
called Clight \autocite{leroy:compcert,blazy2009clight},
though it itself is able to handle most components of the C99 standard.
The main difference between C and Clight is that Clight is \emph{pure};
none of its operations have side effects. It also provides only one loop structure,
an infinite loop that must be broken out of to exit.
Clight has been mechanized in the Coq theorem prover with established
big-step operational semantics, making it a useful subset of C
for program verification work in Coq.

The full proof of \emph{semantic preservation},
as it is called in the CompCert documentation,
is based off of proofs of semantic preservation
for each step in CompCert's compilation process, of which there are twenty.
On top of that, it has eleven different intermediate languages for those steps,
all of which had to be proven semantically equivalent.

Another example of verified compilation is CakeML \autocite{kumar2014cakeml}.
It utilizes a subset of Standard ML modeled with big-step operational semantics.
The main purpose of verified compilation, however,
is not to verify properties over the code.
For example, if the source code is vulnerable to \iac{rop} exploit,
then the assembly code is vulnerable as well.
Verified compilation is thus often accompanied by source code verification.
\todo{elaborate}

More recently, \textcite{chen2018compositional} produced a compositional framework
for the development of certified, \emph{interruptible}%
\index{interrupt}
\ac{os} kernels that use device drivers.%
\index{operating system!kernel}
This was previously a challenge due to the non-local and asynchronous behavior
of hardware interrupts. Their approach uses a general certified device model
with multiple instantiations and provides an effective model of device interrupts.
The verification was done in Coq with the kernel written in Clight.
Once verification was complete, the source code was compiled using a modified version
of CompCert to ensure the semantics were maintained.
They showed the value of their work by taking a preexisting,
non-interruptible, mostly-verified kernel, mCertiKOS \autocite{costanzo2016endtoend},
and extending it to work in their framework along with a couple of device drivers.
In order to deal with devices running in parallel with the \ac{cpu},
device interaction, drivers that are written in a mix of assembly and C,
and properly integrating the correctness proofs for individual components
of the system under test, they did the following.
First, they designed their system architecture such that each device driver
is given its own logical \ac{cpu}, running independently from the core of the kernel.
Then they designed an abstract model of interrupts
based on existing hardware implementations.
The correctness of the system as a whole was shown
by starting from a base machine model
and proving a refinement relation with each layer of abstraction placed on top of it.
As they started off with a mostly-verified kernel, it is likely they would have had
more difficulty if they had started with a kernel
not explicitly designed to be verified. While we did isolate functions
for verification in \cref{ch:cfg}, we did not do so for \cref{ch:syntax}.

\section{Static Analysis}\label{se:static_analysis}
%TODO: No time to elaborate on static analysis, oh well
Static analysis of binary code has also an active research field
for decades  \autocite{kruegel2005automating,brumley2011bap,wang2017angr}.

The BitBlaze project  \autocite{song2008bitblaze,BitBlazeWebSite}
provides a tool called Vine which constructs control flow graphs
for supplied programs and lifts x86 instructions to its own \ac{il}.
Though Vine itself is not formally verified,
it does support interfacing with the aforementioned \ac{smt} solver \ac{stp}
as well as CVC \autocite{barrett2004cvcl,barrett2007cvc3}.

Meanwhile, the tool Infer \autocite{calcagno2011infer}, developed at Facebook,
provides in-depth static analysis of LLVM code to detect bugs in C and C++ programs.
It utilizes separation logic  \autocite{reynolds2002separation}
and bi-abduction to perform its analyses in an automated fashion.
It is designed to be integrated into compiler toolchains
in order to provide immediate feedback even in \ac{ci} scenarios.

The static analysis tool FindBugs, written for Java code,
takes a bit of a different approach from those other two \autocite{hovemeyer2004findbugs}.
Rather than relying on formal methods,
it searches for common (bad practice) code idioms to detect likely bugs.
Some of the common errors it highlights include null pointer dereferences,
objects that compare equal not having equal hash codes,
and inconsistent synchronization.

Another tool, Splint \autocite{evans2002static}, detects buffer overflows
and similar potential security flaws in C code.
It relies on annotated preconditions to derive postconditions
based on the syntactic structure of the code.

The main difference between these static analysis tools and formal verification
is that these tools are generally highly suited to finding bugs
but are not able to prove their absence.
They generally apply techniques that are formally unsound, such as depth-bounded searches.

\begin{table*}
  \centering
  \caption{Overview of Related Assembly and Additional Work}\label{related-table}
  \begin{tabular}{l l l l l}
    \toprule
    \thead{Work} & \thead{Target} & \thead{Approach} & \thead{Applications} & \thead{Verified code} \\
    \midrule
    Clutterbuck\&Carr\'e & SPACE-8080 & \acs*{itp}+\acs*{vcg} & Example func & \num{33} insts \\
    O'Neill et al. & Z8002 & \acs*{itp}+\acs*{vcg} & Jet engine code & \\
    Yu \& Boyer & MC68020 & \acs*{itp} & String funcs & \num{863} insts \\
    Matthews et al. & Tiny/JVM & \acs*{itp}+\acs*{vcg} & CBC enc/dec & \num{631} insts \\
    Goel et al. & x86-64 & \acs*{itp} & word-count  & \num{186} insts \\
    Tan et al. & ARMv7 & ATP & String search & \num{983} insts \\
    Myreen et al. & ARM/x86 & \acs*{dil} & seL4 & \num{9500} \acs*{sloc} \\
    Feng et al. & MIPS-like & \acs*{itp} & Example funcs & \\
    Schlich et al. & ATmega16 & MC & Auto funcs & Around \num{8000} insts \\
    Brauer et al. & \makecell[l]{ATmega16\\Intel MCS-51} & SA+MC & Example progs &
      \makecell[l]{\num{2630} \acs*{sloc}\\
        \num{935} \acs*{sloc}} \\
    \textbf{\cref{ch:cfg}} & x86-64 & \ac*{itp} & HermitCore & \num{2379}+ insts \\
    \textbf{\cref{ch:syntax}} & x86-64 & \ac*{itp}+CG & Xen & \num{12252} insts \\
    \midrule
    Sewell et al. & C & \acs*{tv}+\acs*{dil} & seL4 & \num{9500} \acs*{sloc} \\
    Shi et al. & C/ARM9 & \acs*{atp}+\acs*{mc} & ORIENTAIS & \num{8000} \acs*{sloc}, 60 insts \\
    Dam et al. & ARMv7 & \acs*{atp}+UC & PROSPER & \num{3000} insts \\
    Baumann et al. & ARMv8-A & \acs*{atp}+UC & HAPSOC & \num{8000} \acs*{sloc} \\
    Bevier et al. & PDP-11-like & \acs*{itp}+TV & Full system & \num{3000}+ \acs*{sloc}/insts \\
    \bottomrule
    \multicolumn{5}{c}{
      \small
      \newlength\colseplen
      \setlength\colseplen{1ex}
      \newcommand\colsep{\hspace\colseplen}
      \begin{tabular}{l@{\colsep}c@{\colsep}l l@{\colsep}c@{\colsep}l}
        \acs*{vcg} &=& Verification Condition Generation & \acs*{dil} &=& Decompilation into Logic \\
        \acs*{sloc} &=& Source Lines of Code        & \acs*{atp} &=& Automated Theorem Proving \\
        UC   &=& User Contracts											& CG 	&=& Certificate Generation \\
        TV   &=& Translation Validation							& MC 	&=& Model Checking \\
        SA   &=& Static Analysis & & &
      \end{tabular}
    }
  \end{tabular}
\end{table*}

\section{Summary}
This section covered some of the work related to that presented in this dissertation.
Previous assembly- or lower-level formal verification efforts,
verification efforts containing assembly or binary analysis components,
verified compilation, and static analysis tools were all discussed.

Notably, while multiple assembly-level verification efforts
presented in this chapter achieved more coverage
than the over \num{2379} instructions achieved by the work in \cref{ch:cfg},
none appear to have achieved the \num{12252}
verified instructions covered in \cref{ch:syntax}.
