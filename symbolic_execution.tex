\chapter{Symbolic Execution}\label{ch:symbolic_execution}
Symbolic execution, in a sense,
\index{symbolic execution}
is an extension of symbolic manipulation of mathematical equations.
It involves executing a program with a set of symbolic inputs
rather than concrete values~\citep{king1976symbolic}.
The individual steps of execution are implemented as \emph{rewrite rules}
\index{symbolic execution!rewrite rule}
over the state.
When used in a theorem prover such as Isabelle/HOL,
\index{Isabelle/HOL}
those rules are ideally proven to be correct.

%TODO: more

\section{Machine Model}
The machine model used in this dissertation takes the following general form.
\index{symbolic execution!machine model}
There exists some symbolic \emph{state} defined as a record
\index{state!symbolic}
that stores registers, flags, and 64-bit addressable byte-level memory.
The instructions to be executed are stored in that memory.
Each instruction is executed by a \emph{step} function having the type
\index{symbolic execution!step function}
$A\times S\mapsto(S\mid\bot_E)$.%
\nomenclature{$A$}{Type of assembly instructions}%
\nomenclature{$S$}{Type representing program state; an Isabelle record}%
\nomenclature{$\bot_E$}{Indicates exceptional state}
This function takes a tuple of instruction to execute and current state~$\sigma$,
returning the state~$\sigma'$ after execution of that instruction.
If some sort of exception, such as a divide by zero, occurs,
the function returns $\bot_E$ instead.
% TODO: rework this? Only the SAFECOMP step possibly returns $\bot_E$, I think.

The semantics of the instructions as executed by the step function
\index{semantics}
are those produced by Roessle et al.~\citep{roessle2019},
which built upon the work of Heule et al.~\citep{heule2016}.
Heule et al.\ used machine learning to derive semantics
by executing instructions on an actual x86-64 machine.
Their semantics were validated against the Intel reference manual.
The formal model was obtained by embedding those semantics into Isabelle/HOL.
\index{Isabelle/HOL}
It has been tested against an actual x86-64 machine, increasing the model's reliability.
The model provides a formalization of large parts of the x86-64 \ac{isa},
including several modern instruction set extensions such as the \ac{sse} family.
Concurrency is not included in the model.

From the machine model, we manually derive a run function
\index{symbolic execution!run function}
$\run:(S\mapsto\mathbb{B})\times S\mapsto(S\mid\bot_E\mid\bot_\var{NT})$.%
\nomenclature{$\bot_\var{NT}$}{Indicates non-termination}
This partial function takes as input a state predicate~$H$ and a state~$\sigma$.
\index{state!predicate}
Predicate~$H$ denotes the \emph{halting condition}.
\index{symbolic execution!halting condition}
Typically, the halting condition instructs the run function to stop
at a certain instruction, such as \lstinline{ret}.
The run function iteratively fetches the current instruction
via the current value of the instruction pointer
and uses the machine model to execute it.
Whenever an exception occurs, it stops and returns~$\bot_E$.
If the execution were to continue forever
without an exception or reaching the halting condition
(e.g.\ due to an infinite loop),
the function returns $\bot_\var{NT}$.
Formally, this is achieved by a standard least-fixed-point construction.

% TODO

As the x86-64 \ac{isa} is a little-endian architecture,
\index{endianness!little}
all operations on memory presented in this dissertation are designed with that in mind.
\begin{example}
  Given the state $\{\region{a}{2}\coloneqq\mathtt{0xEEFF}\}$,
  a read of region $\region{a}{1}$ would produce $\mathtt{0xFF}$.
\end{example}
Support for big-endian architectures would require changing how reads and writes
\index{endianness!big}
are performed. For every read and write, the bytes would need to be reversed
in order to use them appropriately.
Some \acp{isa} are even \emph{bi-endian}, allowing both big- and little-endian
\index{endianness!bi}
memory operations. These include modern versions of ARM, PowerPC, SPARC, and MIPS.
Supporting bi-endianness would require additional complexity in memory handling.

\section{Symbolic Execution and Memory Usage}
% TODO: probably need more here
Symbolic execution in Haskell keeps track of all used memory regions,
\index{symbolic execution}
both the actual regions used by instructions as well as merged regions.
\begin{example}\label{ex:simple}
  Consider the following x86-64 assembly block:
  \begin{lstlisting}[style=x64,gobble=4]
    a0: mov    word ptr [rsp-0x8], 0xEEFF
    a1: mov    dword ptr [rsp-0x4], 0xAABBCCDD
    a2: mov    ax, word ptr [rsp-0x7]
    a3: mov    edi, dword ptr [rsp-0x6]
  \end{lstlisting}
  The instructions at addresses \lstinline|a0| and \lstinline|a1|
  write to two separate regions in memory,
  $r_0=\region{\mathrsp-8}{2}$ and $r_1=\region{\mathrsp-4}{4}$.
  Following the writes, the instruction at \lstinline|a2|
  reads from region $\region{\mathrsp-7}{2}$,
  which is merged with~$r_0$ to obtain $r_2=\region{\mathrsp-8}{3}$.
  Reading from region $\region{\mathrsp-6}{4}$
  results in a merge with~$r_2$ and~$r_1$, producing region $\region{\mathrsp-8}{8}$.
  The aggregated assignment is then
  \begin{equation*}
    \region{\mathrsp-8}{8}\coloneqq\mathtt{0xAABBCCDD}\concat
    \takebits{31,16}\region{\mathrsp-8}{8}\concat\mathtt{0xEEFF}.
  \end{equation*}
  The set~$M$ of memory regions for the given block of assembly is ultimately
  \begin{equation*}
    M\equiv\{\region{\rspo-8}{2},\region{\rspo-4}{4},\region{\rspo-7}{2},
    \region{\rspo-6}{4},\region{\rspo-8}{8}\}.
  \end{equation*}
  The \acp{mrr} for~$M$ can be easily established by supplying each pair of regions
  to the Z3 decision procedure mentioned in \cref{sse:memory_aliasing}.
\end{example}

\section{Hoare Logic and Symbolic Execution}
Unlike the usual formulation of Hoare logic~\citep{hoare1969axiomatic,myreen2007hoare},
\index{Hoare!logic}
Hoare triples as defined for the first contribuation of this dissertation
\index{Hoare!triple}
take a halting condition
\index{symbolic execution!halting condition}
as their middle input rather than a program statement.
The program statement is instead characterized by the addresses of its initial
and ending instructions, defined in~$P$ and~$H$.
Thus, we have the following definition:
\begin{definition}\label{def:htriple}
  $\htriple{P}{H}{Q}$
  denotes that, for any state~$\sigma$, assuming precondition~$P$ and termination,
  $\run(H,\sigma)$ produces a non-exceptional state that satisfies postcondition~$Q$.
  
  Formally,
  \begin{equation}
    \htriple{P}{H}{Q}\equiv\forall\sigma\cdot
    P(\sigma)\wedge\sigma'\neq\bot_{\var{NT}}\longrightarrow
    \sigma'\neq\bot_E\wedge Q(\sigma'),
  \end{equation}
  where $\sigma'=\run(H,\sigma)$.
\end{definition}
% TODO: may not need the explicit $\sigma'\neq\bot_E$
 
Standard composition does not apply to such Hoare triples.
Consider a symbolic run that executes until halting condition~$H'$.
\index{symbolic execution!halting condition}
It is possible to break this run into two parts
by first running until a halting condition~$H$ and then until~$H'$.
This requires that~$H'$ is \emph{stronger} than~$H$; that is, $H'$ implies~$H$.
This ensures that the run first stops at~$H$ before it stops at~$H'$.
%\refstepcounter{equation}
\begin{theorem}\label{thm:comp}
  Hoare triples are compositional with respect to stronger halting conditions:
  %  \def\labelSpacing{24.574 pt}
  \begin{prooftree}
    \AxiomC{$\htriple{P}{H}{Q}$}
    \AxiomC{$\htriple{Q}{H'}{R}$}
    \AxiomC{$\forall\sigma\cdot H'(\sigma) \longrightarrow H(\sigma)$}
    %    \LeftLabel{\hphantom{\textnormal{(\theequation)}}}
    %    \RightLabel{\textnormal{(\theequation)}}
    \TrinaryInfC{$\htriple{P}{H'}{R}$}
  \end{prooftree}
\end{theorem}

\section{Hoare Triples for Memory Usage}\label{se:hoare2}
This formulation, $\htriple*{P}{f}{Q}{M}$,
resembles traditional Hoare triples a bit more,
\index{Hoare!triple}
as rather than a halting condition
it takes a syntactic representation of the program,~$f$, known as \emph{\ac{scf}}.
Unlike traditional Hoare triples, however,
it also explicitly contains the set of memory regions,~$M$,
that enumerate the areas of memory read and written by the program
the \ac{scf} encodes.
\Ac{scf} is a representation of the control flow of a function
in terms of syntactic structures such as basic blocks,
loops, and if-then-else statements.
Syntactic structure is required because Hoare logic is a syntax-guided approach.

\todo\dots

\begin{definition}\label{def:usage}
  A memory usage Hoare triple is defined as
  \begin{equation*}
    \htriple*{P}{f}{Q}{M}\equiv
    \forall\sigma~\sigma'\cdot P(\sigma)\wedge\exec(f,\sigma,\sigma')\longrightarrow
    Q(\sigma')\wedge\usage(M,\sigma,\sigma')
  \end{equation*}
  The above equation states the following:
  if precondition~$P$ holds on the initial state~$\sigma$
  and~$\sigma'$ can be obtained by executing~$f$,
  postcondition~$Q$ holds on the produced state
  and the values stored in all memory regions outside set~$M$ are preserved.
\end{definition}
While \cref{def:usage} focuses on the regions written to,
the regions read must also be included as symbolic execution
relies on those regions being included.
Without them, proofs involving symbolic execution
of the related instructions will not complete.

\todo{Discuss how it can be an overapproximation
  due to necessities of loops/etc.\ in Hoare triples/etc.}

\section{Hoare Rules for Memory Usage}\label{se:hoare_rules}
% TODO: mention \acp{vcg} that apply the rules
