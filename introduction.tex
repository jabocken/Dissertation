\chapter{Introduction}
% TODO

The approaches to assembly-level verification detailed in this dissertation%
\index{assembly!verification}
are \emph{semi-automated},
as the non-trivial memory usage-related properties presented here are undecidable
per Rice's theorem~\citep{rice1953classes}.
The usage of \iac{itp} environment allows user interaction when necessary,
while the automated generation
of at least some components of formal proofs
reduces the amount of manual proof effort required by varying degrees.

\section{Motivation}
\todo\dots
\subsection{Importance}
\todo\dots
\todo{Why is software verification important?}

\subsection{Challenges}
\todo\dots
Highly-automated verification efforts are desirable, but do not necessarily scale.
Model checking

\section{Assembly-Level Verification}
\todo\dots

\subsection{Importance}
Properties that reason over the concrete memory used by a program
cannot be satisfactorily expressed on the source-code level.
This is because even programs in a relatively low-level language like C
have abstractions on memory for local variables and function calls.
How and where that memory is allocated may be compiler, \ac{abi}, and \ac{isa}-specific.
It can even depend on what compiler options are in use,
including the level of optimization.
While one way of resolving that issue would be to choose a specific compiler
and provide a formal analysis of how it arranges memory (or write a compiler to do so),
that method places restrictions on the build process.
Targeting assembly or machine code directly, as done in this dissertation,
allows bypassing the build process, opening the door for verification of legacy code.
\begin{example}\label{ex:rop}
  As a further illustration, consider formulating a property
  that a function cannot overwrite its own return address.
  Doing so would require knowledge of the layout of the stack,
  including the values of the stack and frame pointers,
  thus making it an \emph{assembly-level} property.
\end{example}

\subsection{Challenges}
The biggest challenge in assembly-level verification is
the semantic gap between compiled and source code.
Higher-level languages hide details of their implementation
behind layers of abstraction, which makes it easier to reason about them on that level
but makes it harder to formally show equivalence with the semantics of
to lower abstraction levels.
Meanwhile, assembly languages are close to direct interfaces
with their corresponding \acp{isa},
having minimal differences in semantics but not being easy to reason about directly.

As an example of the semantic gap,
assembly code generally lacks the structured control flow found in languages
on a higher level of extraction.
Instead, all control flow on the assembly level is performed using conditional
or unconditional branches, either to a predetermined location
or to a calculated label.

A further example would be source code containing division operations
being compiled to run on a processor that does not provide hardware division.
Many \acp{cpu} for embedded systems lack support for hardware division
as efficient division algorithms require a lot of circuitry.
For such processors, runtime division must be calculated using an algorithm
implemented in assembly rather than via a specific instruction.

Even the basic concept of numeric types is minimal on the assembly level,
much less more abstract data types like lists or trees.
While most \acp{isa} do have different instructions
for signed versus unsigned integer arithmetic,
as well as distinct instructions for floating-point operations,
individual values in memory have no type.
They are merely lists of bytes starting at some address,
and even the number of bytes and the address to read from or write to can be variable.
A user could go as far as supplying the result of a floating-point computation
as the address operand of an instruction that loads or stores memory.
Historically, there have been computers that associated type information
with memory locations in hardware~%
\citep{feustel1972rice,feustel1973advantages,thornton2008rice},
but we do not have that luxury on typical modern systems.

An additional issue with assembly,
and the one most significant for this dissertation,
lies in the simplicity of the user-exposed memory model.
The vast majority of high-level, structured languages with scoping
prevent function calls from accessing the local variables of other calls
without significant effort or explicit notation, but the same is not true for assembly.
An assembly instruction that operates on memory can refer to any
address within range of its address operands even if it is not supposed to.
Most modern \acp{isa} do provide some form of memory protection,
but those generally rely on runtime detection of invalid accesses
and are often not fine-grained enough for reasoning about individual stack frames
or local variables.
Any verification effort that wishes to reason about low-level memory properties
must provide its own abstractions and assumptions on layout.

\subsection{State of the Art}
\todo\dots

\section{Contributions}
This dissertation presents two formal methodologies for function-oriented verification
of the assembly-level property we call \emph{memory usage},
described in \cref{memory_usage}.
Both methodologies use some form of control-flow analysis over x86-64 assembly code
to generate incomplete proofs
that are then loaded into the interactive theorem prover Isabelle/HOL
and completed there. The process of completing those proofs involves
\emph{symbolic execution}~\citep{king1976symbolic} of the underlying assembly code.

\todo\dots

\subsection{Memory Usage}\label{memory_usage}
This property characterizes the regions in memory that are read and written by a program
and shows that the values written by that program are constrained to those regions.
The following sections elaborate on the usefulness of memory usage
as a platform for further verification efforts.

\subsubsection{Security}
Unbounded memory usage can lead to vulnerabilities
such as buffer overflows and data leakage.
One example of such a vulnerability would be 2014's Heartbleed~\citep{heartbleed}.
Heartbleed was caused by a lack of bounds checking on a string array
requested as output as part of a ``heartbeat'' message.
This, combined with a custom memory manager
that also had no security protections against out-of-bounds memory accesses,
lead to potential leakage of sensitive data such as passwords and encryption keys.
Memory usage could serve as a foundation for formal security analyses
that could be used to expose vulnerabilities involving malicious writes.

Another important property that memory usage could help with
is \emph{\ac{cfi}}~\cite{abadi2009cfi}. \Ac{cfi} ensures that software execution
follows a predetermined \ac{cfg} using static analysis and runtime checks.
The dynamic checking could be made more efficient
by first proving the property in \cref{ex:rop} for those functions it is applicable to
and then leaving out any return-oriented checks for those functions it holds on.
This could be one way of avoiding \ac{rop} attacks without excessive runtime overhead.

The property of \emph{noninterference} is also a useful one for security.
It requires reasoning over which parts of the memory are used by which functions~\citep{rushby1992noninterference},
and memory usage is ideal for such a scenario.

\subsubsection{Composition}\label{sse:composition}
Scalability in verification is only feasible with composition;
proofs of functional correctness or some other property over a large suite of software
require decomposing that suite into manageable chunks.
Separation logic provides a \emph{frame rule} that supports such%
\index{separation logic!frame rule}
decomposition~\citep{o2001local,reynolds2002separation,krebbers2017essence}.
In words, the frame rule states that,
if a program or program fragment can be confined to a certain part of a state,
properties of that program or program fragment carry over
when used as part of a larger system involving that state.
Memory usage allows for discharging the most involved part of the frame rule,
at least in terms of individual assembly functions.
That is, it shows that the memory usage of those functions is constrained
to specific regions in memory.
This could then serve as a basis
for a larger proof effort over multi-function assembly programs.

\subsubsection{Concurrency}
Reasoning over concurrent programs is complicated
due to the potential interactions between threads.
While there are ways of handling such interactions in a structured manner
via kernel- or library-provided \ac{ipc},
one method commonly used for the sake of efficiency is \emph{shared memory}.
Shared memory, in the context of this work,
refers to threads or processes sharing either a full memory space
or portions of one (via memory mapping)
that can be written to and read from freely by any thread or process with access to it.
Usage of shared memory can result in \emph{unintended} interactions between threads.
Memory usage could be adapted to show the absence of such interactions
by proving that multiple threads only write
to specifically-allowed regions of shared memory.
Doing so would, of course, require a proper model of concurrency,
which is out of scope of this dissertation.


\subsection{Summary}
In summary, this dissertation contributes 
\begin{itemize}
  \item 
  \item \ac{cfg}-Driven Verification
  \begin{itemize}
    \item 
  \end{itemize}
\end{itemize}
  
* Safecomp
** Formal definition of Memory Preservation
** Formal method of verifying it
* Popl
** Mostly-automated methodology for memory usage verification
** Analysis of Xen binaries

\section{Organization of Dissertation}

\todo\dots
Domain-specific information necessary to understand the work
can be found in \cref{ch:background}.
\todo\dots
