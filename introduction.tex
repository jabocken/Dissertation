\chapter{Introduction}
\todo{Preamble structure: 1 par intro, 1 par overview, 1 par attribution if necessary}

% TODO

The approaches to assembly-level verification detailed in this dissertation%
\index{assembly!verification}
are \emph{semi-automated},
as the non-trivial memory usage-related properties presented here are undecidable
per Rice's theorem~\citep{rice1953classes}.
The usage of \iac{itp} environment allows user interaction when necessary,
while the automated generation
of at least some components of formal proofs
reduces the amount of manual proof effort required by varying degrees.

\section{Motivation}
\todo{Why is software verification important?}

\section{State of the Art in Assembly-Level Verification}

\section{Memory Usage}\label{memory_usage}
\todo{move to contributions}
The main property targeted for verification in this dissertation
is referred to here as \emph{memory usage}.%
\index{memory!usage}
It characterizes the exact addresses in memory
that are read and written by a program.
Because of this specificity, memory usage cannot be satisfactorily expressed
on the source-code level.
This is because even programs in a low-level language like C
have memory that is allocated for internal rather than user use,
and how and where that memory is allocated may be compiler, \ac{abi},
or \ac{isa}-specific.

As a further illustration,
consider formulating a property
that a function cannot overwrite its own return address
(one way of protecting from \ac{rop} attacks).
Doing so would require knowledge of the layout of the stack,
including the values of the stack and frame pointers,
thus making it an \emph{assembly-level} property.

\subsection{Memory Preservation}
An application of memory usage analysis,
memory preservation shows that the values written by a program%
\index{memory!preservation}
are constrained to specified regions in memory.
Those regions cannot be fully identified when working with source code alone,
particularly when the end result is optimized.
Memory may be laid out differently depending on the \ac{isa} and \ac{abi} targeted,
as well as on the compiler used.
This can include positioning of global variables
as well as the layout of stack frames.\index{stack!frame}
While one way of resolving that issue would be to choose a specific compiler
and provide a formal analysis of how it arranges memory, that method is not flexible.
It may instead be better to target assembly or machine code directly,
as done in this dissertation.

\subsubsection{Usefulness}
The following paragraphs elaborate on the usefulness of memory preservation
as a platform for further verification efforts.

\paragraph{Security.}
Unbounded memory usage can lead to vulnerabilities
such as buffer overflows and data leakage.
One example of such a vulnerability would be 2014's Heartbleed~\citep{heartbleed}.
Heartbleed was caused by a lack of bounds checking on a string array
requested as output as part of a ``heartbeat'' message.
This, combined with a custom memory manager
that also had no security protections against out-of-bounds memory accesses,
lead to potential leakage of sensitive data such as passwords and encryption keys.
% TODO: need another, better example that involves data modification too?
Memory preservation could serve as a foundation for formal security analyses
that could be used to expose vulnerabilities involving malicious writes.

\paragraph{Composition.}\label{sse:composition}
Scalability in verification is only feasible with composition.
Proofs of functional correctness over a large suite of software
require decomposing that suite into manageable chunks.
Separation logic provides a \emph{frame rule} that supports such%
\index{separation logic}%
\index{separation logic!frame rule}
decomposition~\citep{o2001local,reynolds2002separation,krebbers2017essence}.
In words, the frame rule states that,
if a program or program fragment can be confined to a certain part of a state,
properties of that program or program fragment carry over
when used as part of a larger system involving that state.
Memory preservation allows for discharging the most involved part of the frame rule,
at least in terms of individual assembly functions.
That is, it shows that the memory usage of those functions is constrained
to specific regions in memory.
This can then serve as a basis
for any larger proof effort over multifunction assembly programs.

\paragraph{Concurrency.}
Reasoning over concurrent programs is complicated
due to the potential interactions between threads.
While there are ways of handling such interactions in a structured manner
via kernel- or library-provided \ac{ipc},
one method commonly used for the sake of efficiency is \emph{shared memory}.
Shared memory, in the context of this work,
refers to threads or processes sharing either a full memory space
or portions of one (via memory mapping)
that can be written to and read from freely by any thread or process with access to it.
Usage of shared memory can result in \emph{unintended} interactions between threads.
Memory preservation could be adapted to show the absence of such interactions
by proving that multiple threads only write
to specifically-allowed regions of shared memory.
Doing so would, of course, require a proper model of concurrency,
which is out of scope of this dissertation.

\subsection{Overapproximation}\label{mem_use_over}
As a formal property, memory usage has been proven to never miss any memory regions
written to, assuming the correctness of the semantics and model it is applied
to~\citep{bockenek2019preservation,popl2019underreview}.
Put another way, however,
this means that the methodology \emph{must} be conservative.
If it cannot make a determination about the usage status of some part of memory,
either due to an underdeveloped state or too large of one to easily reason about,
it must assume that that region is used. It must \emph{overapproximate}.%
\index{overapproximation}
This sort of false positive can be an issue in the field of formal verification,
as it can make the property under consideration weaker despite being correct.

One way to shrink such overapproximations is to increase the
\emph{context sensitivity}\index{context sensitivity}
of the approach, such as performing the analysis over the full program at once
rather than individual components, but that can involve
a significant increase in time and verification effort.

\todo{Want talk about the usage of SMT solvers/etc.,
  increase in automation in general
  as one way of mitigating increased verification effort somewhere}

%\section{Challenges of Assembly-Level Verification}
%The biggest challenge of assembly-level verification is the lack of abstraction.
%Higher-level languages hide details of their implementation
%behind layers of abstraction, which makes it easier to reason about them
%on that level.

\section{Research Contributions}
The main contributions of this dissertation
* Safecomp
** Formal definition of Memory Preservation
** Formal method of verifying it
* Popl
** Mostly-automated methodology for memory usage verification
** Analysis of Xen binaries

\todo{bullet points after explanation}

\section{Organization of Dissertation}
\todo{summary}
