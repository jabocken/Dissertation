\chapter{Discussion}\label{ch:hg-discussion}
Having covered the basic concepts (\cref{ch:hg-lifting}), formulation (\cref{ch:hg-formulation}), and experimental results (\cref{ch:hg-discussion}) of \acp{hg}, we draw to an end for this  \namecref{hg} of my dissertation.
This \namecref{ch:hg-discussion} wraps things up with a high-level discussion of how the assumptions we made in \cref{cfr-assumptions} affect the usability of overapproximative binary lifting in various application domains.
It also covers the importance of the per-instruction disassembler (a part of the \ac{tcb}) being correct.

This \namecref{ch:hg-discussion} was again a joint effort with the co-authors of the original paper \autocite{verbeek2022lifting}.

\section{Security Analysis}
The central claim in this paper is that \emph{if} all assumptions and proof obligations are met,
\emph{then} the lifted representation is a sound overapproximation of the binary.
\Cref{sec:not-me-failures} showed an example where an assumption can be violated: \inlineasm{memset} may not preserve the indicated region.
The negation of assumptions required for ``normal'' behavior may lead to ``weird'' behavior.
In other words, the negation of the generated assumptions may be useful in the generation of exploits.
A key challenge here is to filter out the relevant (exploitable) assumptions from the irrelevant ones.

\section{Binary Verification}
We argue that the majority of existing work on binary verification \emph{assumes} the existence of a trustworthy disassembler.
This work exposes and makes explicit assumptions that otherwise may remain implicit.
Therefore, basing a verification effort on a verified \ac{hg} instead of directly on the output of any of-the-shelf disassembler reduces the \ac{tcb} of the verification effort.

\section{Decompilation}
Similarly, we argue that the majority of existing decompilation tools \emph{assume} the existence of a reliable disassembler.
A verified \ac{hg} is a reliable base for decompilation.
For example, the provably correct assembly and control flow inferred by our approach could be used as input to McSema \autocite{dinaburg2014mcsema} in order to produce provably correct LLVM code.
\todo{glossary entry for LLVM}
The assumptions then may be translated to higher-level \inlineasm{assert}-statements: the decompiled code is correct as long as no assert is triggered.

\section{Patching}
Binary patching typically either involves some stages of decompilation, or replacing snippets of assembly instructions with different ones \autocite{duck2020binary}.
We argue that lifting both an original binary and its patched version to \acp{hg} would increase the trustworthiness of the patch effort.
Both the \acp{hg}---but also the assumptions required for lifting the binaries---could be mutually compared, and this comparison may expose unexpected effects of the patch.

\section{Don't Forget to Check Your Disassembler!}
The library we were originally using to interpret the binary representation of individual instructions did not correctly identify the size of operands for certain instructions, such as some \ac{simd} ones.
That size differential had the potential to cause bad semantics or even errors in Z3\index{Z3} usage due to incorrect typing and value truncations or lack thereof.
However, we did not uncover this issue until a compatriot (Ian Roessle) noticed incorrect disassembly output while working on a separate project using a portion of our codebase.
To solve this issue, we switched to Capstone \autocite{capstone}.
When tested on the binary our compatriot was working with, the individual instructions were extracted as expected.

This is an example of why it is important to reduce the \ac{tcb} as much as possible.
If your assumptions of trust are misplaced, such as an unverified component of your disassembler being buggy, the results as a whole have the potential to be wrong.
